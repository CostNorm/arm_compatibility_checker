# 이제 LLM기반 챗봇 에이전트가 **구체적으로 어떻게 비용 최적화 지점을 식별하고, 사용자에게 통지한 후, 실제 최적화 작업을 수행하는지** 상세히 설명하겠습니다

---

## 💡 에이전트의 구체적인 기능 (LLM Function 설계)

챗봇 에이전트는 클라우드 비용 최적화를 위해 다음과 같은 **구체적인 함수(Function) 세부 정의 및 흐름**을 통해 동작합니다.

### [✅ [Function 1] 최근 과금 데이터 분석 및 비용 효율적이지 않은 EC2 인스턴스 식별](pplx://action/followup)

#### ‣ 목적

- AWS Cost Explorer API를 호출해 최근 2~7일 비용 데이터를 받아옴
- 특정 EC2 자원의 비용 증가 패턴이 나타나면 이상 탐지 실행

#### ‣ 동작 방식

1. 매일 정기적으로 Lambda를 통해 AWS Cost Explorer API 호출 (매일 UTC 0시 기준, 최근 2일 데이터 비교)

```python
import boto3
from datetime import datetime, timedelta

client = boto3.client('ce')
response = client.get_cost_and_usage(
    TimePeriod={
        'Start': (datetime.utcnow() - timedelta(days=2)).strftime('%Y-%m-%d'),
        'End': datetime.utcnow().strftime('%Y-%m-%d')
    },
    Granularity='DAILY',
    Metrics=['AmortizedCost'],
    GroupBy=[{'Type': 'DIMENSION', 'Key': 'SERVICE'}, {'Type': 'DIMENSION', 'Key': 'RESOURCE_ID'}]
)
```

2. 해당 결과를 LLM 모델에게 JSON 형태로 전달하여 이전 데이터 대비 비용 급증을 자동으로 점검
   - 이상 패턴: 전날 대비 금일 자원 비용이 20%~30% 이상 증가할 경우 이상으로 간주
3. 이상 발견 시 Slack 또는 지정한 메신저로 자동 알림

---

### [✅ [Function 2] RI/ Savings Plans 구매 추천 자동화](pplx://action/followup)

#### ‣ 목적

- 지속적으로 동일한 워크로드가 On-Demand로 실행 중일 때, RI 또는 Savings Plans 전환 추천

#### ‣ 동작 방식

1. AWS Cost Explorer "GetSavingsPlansPurchaseRecommendation" API 호출로 AWS가 미리 분석한 추천 정보를 얻어옴

```python
recommendation = client.get_savings_plans_purchase_recommendation(
    LookbackPeriodInDays='THIRTY_DAYS',
    SavingsPlansType='COMPUTE_SP',
    PaymentOption='PARTIAL_UPFRONT'
)
```

2. 추천된 데이터 중 할인률이 30% 이상인 항목만 필터링하여 사용자에게 아래 형식으로 메시지 통보

```
추천: EC2 인스턴스 c5.large(On-Demand) 3대를 1년 Compute Savings Plan으로 구매하면 매월 $150 (35%) 절약 가능합니다.
Slack에서 '구매'를 입력하시면 자동으로 처리됩니다.
```

3. 사용자가 "구매"를 입력하면 자동으로 Savings Plans를 구매 (`create_savings_plan` API 호출)

---

### [✅ [Function 3] ARM64(Graviton)로 이전 가능한 자원 식별 및 자동 이전 진행](pplx://action/followup)

#### ‣ 목적

- 기존의 x86 기반 EC2 인스턴스가 ARM64로 전환 가능한지 자동으로 조사하고 추천

#### ‣ 식별 방법

1. AWS Compute Optimizer를 통해 추천 정보를 받아 전환 가능성을 파악

```python
compute_optimizer = boto3.client('compute-optimizer')
response = compute_optimizer.get_ec2_instance_recommendations()
```

2. 추천정보 JSON 중, "finding": "OVER_PROVISIONED" 혹은 ARM64 기반 인스턴스를 추천하는 항목만 필터링
3. 사용자에게 추천 메시지 전송

```
추천: EC2 인스턴스(m5.large) → ARM64(m6g.large) 전환 시, 월 $50(약 20%) 절감 및 최대 30% 성능 향상 예상.
Slack에서 전환을 희망하시면 'ARM64 전환'이라고 입력해주세요.
```

#### ‣ 자동 전환 수행 절차

- 사용자가 "ARM64 전환" 입력 시 수행:
  1. 기존 인스턴스 이미지(AMI 생성)를 통해 ARM64 호환 이미지 생성
     - 사전 준비된 Amazon Linux 2 ARM64 AMI에 기존 배포 스크립트(Ansible, User data)를 적용하여 새 이미지 생성
  2. ARM64 기반의 신규 Auto Scaling Group 또는 개별 인스턴스를 생성
  3. 신규 인스턴스 정상 동작 확인 후, 기존 인스턴스를 종료 및 리소스 청소

---

### [✅ [Function 4] Spot Instance 자동 전환 및 관리를 위한 식별 및 이전 작업 자동화](pplx://action/followup)

#### ‣ 목적

- 기존 On-Demand 인스턴스들을 Spot Instance로 전환할지 자동으로 분석, 추천 및 실행

#### ‣ 동작 방식

1. 이미 Auto Scaling 그룹을 이용 중이라면, 현재 인스턴스의 활용도와 유형을 점검

```python
asg = boto3.client('autoscaling')
response = asg.describe_auto_scaling_groups(AutoScalingGroupNames=['existing-asg'])
```

2. 충분히 분산되어 있고, 중단에 내성이 있는 자원이면 Spot 혼합 구성 추천

```
추천: ASG(web-app-asg)를 Spot Instance 혼합모드로 변경시 약 60% 비용 절약 가능.
Spot 혼합모드를 적용하시려면 'Spot 적용' 입력해주세요.
```

#### ‣ 자동 적용 방법

- Slack에서 사용자가 'Spot 적용' 입력 시:

```python
response = asg.update_auto_scaling_group(
    AutoScalingGroupName='web-app-asg',
    MixedInstancesPolicy={
        'InstancesDistribution': {
            'OnDemandPercentageAboveBaseCapacity': 20,
            'SpotAllocationStrategy': 'capacity-optimized'
        },
        'LaunchTemplate': {
            'LaunchTemplateSpecification': {
                'LaunchTemplateId': 'lt-xxxxxxxx',
                'Version': '$Latest'
            },
            'Overrides': [
                {'InstanceType': 'c5.large'},
                {'InstanceType': 'c5a.large'},
            ]
        }
    }
)
```

---

## 📌 Function들의 구조 및 호출 과정

실제 LLM(Chatbot)은 Slack 대화에서 `Function calling 기법`을 활용해 요청을 식별하고 위의 함수를 호출합니다.

```json
{
  "name": "recommend_arm64_migration",
  "description": "Identify EC2 Instances that can migrate to ARM64 and apply migration.",
  "parameters": {
    "instances": ["i-0123xxxx", "i-0a45yyyy"]
  }
}
```

LLM은 위와 같은 Function 호출을 Json 형태로 Lambda에 전달하고, Lambda 내부의 Python 코드(boto3 등 AWS SDK 활용)가 실제 작업 실행을 담당합니다.

---

## 📅 일반 작업 주기 및 타임라인 관리 (자동 통지)

- AWS Cost Explorer API를 통해 **매일 일정 시간** 비용 데이터를 자동 분석
- 이상 비용이 나타나면, 자동으로 LLM이 Slack을 통해 사용자에게 통지
- 사용자가 챗봇과 대화형 상호작용을 통해 (`"구매", "전환", "적용"` 입력 등) 쉽게 작업을 승인하면 즉시 적용 실행됨

---

## 📈 이 구조의 장점과 기대 효과

- **자동화된 비용 절감**: 반복적이고 까다로운 비용 관리 작업을 최소화하고, 즉시 실행 가능
- **실시간 모니터링과 대응**: 빠르게 비용 이상 징후를 탐지하여 실시간 대응 가능
- **사용자 편의성 증대**: Slack 내에서 자연어 기반으로 쉽게 비용 최적화 작업 처리 가능

이러한 방식으로 명확하게 정의된 Function 구조와 구체적인 AWS API 호출 및 SDK 코드 예제로 구성된 시스템을 통해, 비용최적화 챗봇 에이전트를 성공적으로 구축할 수 있습니다. 🚀✨
