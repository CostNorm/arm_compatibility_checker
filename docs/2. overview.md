# 📖 요약: 보고서 핵심 요점 재검토

보고서에서는 EC2 중심으로 다음과 같은 비용 최적화 전략을 다루었습니다.

- **적합한 인스턴스 구매 방식 선택**: On-Demand, Reserved Instances(RI), Savings Plans, Spot Instance
- **Spot Instance 적극 활용**: 최대 90% 비용 절감 가능하지만 갑작스런 종료 위험 있음
- **Auto Scaling**: CPU, 메모리, 요청량 등 사용량 기반 자동 증감으로 효율적 자원 관리
- **ARM64(Graviton 기반)로의 마이그레이션**: 기존 x86 대비 약 20% 비용 절감 효과 및 최대 40% 성능 개선
- **서버리스 환경 병행 검토**: Lambda / Fargate로 특정 워크로드 이전하여 비용 절감 가능
- **지속적인 모니터링 및 조정**: AWS Cost Explorer, Budgets, Compute Optimizer 활용

이 내용을 바탕으로, 다음과 같은 방법론을 통해 LLM 기반의 비용 최적화 AI 에이전트를 구축할 수 있습니다.

---

## 🚀 LLM 기반 비용 최적화 AI Chatbot 에이전트 구축 가이드

이 챗봇 에이전트는 사용자의 AWS 환경을 자동 모니터링하여 비용 절감 가능 요소를 찾아내고, 최적화 방법을 제안하며, 사용자의 허락을 받아 설정 작업을 실제로 AWS에 자동 적용할 수 있습니다.

### 📌 Step 1: 프로젝트 초기 환경 구성

- **AWS Bedrock** 활용하여 LLM 모델(Meta LLama, Anthropic Claude 등)을 배포하여 Fine-tuning 환경 준비
- **AWS Lambda 및 Serverless Framework**를 활용하여 서버리스 기반의 chatbot backend 구축
- **Slack(주요 메신저)** 연동을 위한 Integration 설정 (Slack App 생성, OAuth 인증 등)

---

### 📌 Step 2: LLM Chatbot 주요 역할 및 기능 정의

- 주기적으로 AWS Cost 데이터를 분석하고, 비용 리포트를 Slack으로 발송
- 비용이 급격히 상승하거나 비효율적인 요소 발견 시, 사용자에게 최적화 제안을 Slack 메시지로 전달
- Slack 메시지를 통한 사용자 승인 후, 실제 AWS EC2 설정 변경 작업 자동 실행(Spot 구성, RI 구매 등)

---

### 📌 Step 3: 비용 최적화 챗봇 내 기능(Function calling) 구성

다음 주요 기능을 **Function Calling API** 형태로 별도 Lambda Function으로 구현하여 LLM이 호출할 수 있게 합니다.

| 기능(Function)                       | 수행 역할 및 설명                                                           |
| ------------------------------------ | --------------------------------------------------------------------------- |
| **list_high_cost_instances**         | 최근 과금 데이터 분석 후, 높은 비용을 발생시키는 EC2 자원 자동 식별 및 보고 |
| **switch_to_spot_instances**         | 사용자 승인 시 EC2 Auto Scaling 그룹을 Spot Instance 혼합 모드로 자동 변경  |
| **recommend_reserved_instance_plan** | 안정적인 이용 패턴 기반으로 RI 구매 추천 및 비용 절감 예상액 보고           |
| **apply_reserved_instance_plan**     | 사용자 승인 시 RI 또는 Savings Plan 자동 구매 및 설정 적용                  |
| **implement_arm64_migration**        | Graviton 기반 ARM64로 전환이 가능한 자원 식별 및 자동 이전 절차 수행        |
| **setup_auto_scaling_policy**        | 적절한 CPU 사용률(50~60%) 타겟 Auto Scaling 정책 자동 적용                  |
| **check_serverless_candidate**       | 서버리스(Lambda/Fargate)로 전환이 적합한 워크로드 추천                      |

---

### 📌 Step 4: 실제 동작 시나리오 예시 (Workflow)

아래는 LLM chatbot이 일상적으로 사용자와 상호작용하는 예시입니다.

```text
🔔 [일일 AWS 비용요약 리포트]
- EC2 비용: $120 (어제 대비 15% 증가)
- 주요 원인 인스턴스: EC2 c5.large (On-Demand) 2대, 월간 약정 없음.

💡 추천:
"이 인스턴스를 Spot Instance로 전환하면 약 월 $80(최대 70%) 절감 가능합니다. 전환하시겠습니까? ('예' 입력 승인)"
```

사용자가 "예"를 입력하면, Function calling을 통해 `switch_to_spot_instances` 함수가 Lambda 상에서 AWS API를 호출하여 자동 실행합니다.

---

### 📌 Step 5: 세부 기술 스택 및 설정 방법

다음과 같은 기술적 요소가 개발 과정에서 활용될 것입니다.

| 기술 요소                 | 역할 및 상세 기술 적용 방식                                 |
| ------------------------- | ----------------------------------------------------------- |
| **AWS SDK (boto3)**       | Lambda에서 AWS 자원(EC2 등)을 제어하기 위한 API 호출        |
| **AWS CloudWatch API**    | EC2 AutoScaling 정책 및 알람 자동 설정                      |
| **AWS Cost Explorer API** | 일일 비용 데이터 자동 조회 및 분석                          |
| **Slack API**             | 사용자 메시지 상호작용 및 알림 메시지 전송                  |
| **AWS Lambda & IAM**      | 자동 최적화 작업 실행을 위한 서버리스 실행환경 및 권한 관리 |

**예시 코드 (Lambda + boto3): Spot Instance 자동 전환**

```python
import boto3

def lambda_handler(event, context):
    client = boto3.client('autoscaling')
    response = client.update_auto_scaling_group(
        AutoScalingGroupName=event["ASGName"],
        MixedInstancesPolicy={
            "LaunchTemplate": {
                "LaunchTemplateSpecification": {
                    "LaunchTemplateId": event["LaunchTemplateId"],
                    "Version": "$Latest"
                },
                "Overrides": [
                    {"InstanceType": "c5.large"},
                    {"InstanceType": "c5a.large"},
                    {"InstanceType": "m5.large"}
                ]
            },
            "InstancesDistribution": {
                "OnDemandPercentageAboveBaseCapacity": 20,
                "SpotAllocationStrategy": "capacity-optimized"
            }
        }
    )
    return {"status": "success"}
```

LLM chatbot은 이 Lambda를 호출하여 자동 작업을 수행합니다.

---

### 📌 Step 6: 지속적 개선 및 모니터링 구축

- **Amazon CloudWatch**를 통해 Lambda, AWS SDK 호출 실패/성공 여부를 지속 모니터링하고 Slack으로 알람 발송
- **AWS Cost Anomaly Detection**을 추가 연계하여 비용 이상 탐지 알람을 자동으로 Slack에 발송
- **지속적 Slack 사용자 피드백 수집**을 통해 LLM 모델의 prompt 및 Fine-tuning 데이터 지속 개선

---

## 🎯 결론 및 기대 효과

이 챗봇 시스템을 통해 사용자는 최소한의 노력으로 지속적이고 효과적으로 AWS EC2 비용을 최적화할 수 있게 됩니다. 특히, 다음과 같은 명확한 기대 효과를 얻을 수 있습니다.

- LLM의 자연어 이해 능력을 활용한 직관적이고 쉬운 비용 관리
- 반복적이고 복잡한 AWS 설정 작업 자동화로 관리 효율성 증대
- 실시간으로 비용 최적화 기회를 포착하여 즉시 대응 가능
- 지속적인 모니터링과 피드백을 통한 장기적인 비용 관리 전문성 확보

이러한 접근을 바탕으로, 팀이 더욱 혁신적이고 효율적인 클라우드 환경을 운영하게 될 것입니다.

Citations:
[1] <https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/38816638/30123464-19e9-4ead-b15f-600b65e0672f/paste.txt>

---

Perplexity로부터의 답변: pplx.ai/share
