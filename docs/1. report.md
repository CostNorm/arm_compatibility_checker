AWS EC2 중심의 비용 최적화 전략을 심층적으로 조사하여, 실무에서 즉시 적용 가능한 자료를 제공하겠습니다.

- **EC2 중심**으로 최적화 방법 연구하며, 필요 시 Lambda, Fargate를 비교 수단으로 포함
- **API 호출, SDK 코드 예제, AWS CLI 명령어 등 실무적 자료 포함**
- **Azure/GCP 등 타 클라우드 비교는 생략**, 단 유의미한 사례가 있다면 간략히 언급
- **스타트업, 엔터프라이즈(R&D 포함) 등의 최적화 사례 포함**

# AWS EC2 인스턴스 비용 최적화 전략 심층 조사

## 1. 컴퓨팅 비용 최적화 전략 연구

AWS EC2 인스턴스 비용을 최소화하려면 **인스턴스 구매 옵션 최적화**, **자동 스케일링 활용**, **적절한 인스턴스 유형 선택** 등의 다각적인 접근이 필요합니다. 여기서는 On-Demand, Reserved, Savings Plans, Spot 인스턴스와 Auto Scaling을 활용한 **EC2 중심 비용 절감 전략**을 구체적으로 살펴보겠습니다. 또한 필요한 경우 Lambda, Fargate 같은 서버리스 대안을 비교하여 언제 EC2를 대체할 수 있는지 언급합니다.

### On-Demand vs Reserved 인스턴스 vs Savings Plans

- **On-Demand 인스턴스**: 사용한 만큼 시간 단위로 과금되는 유연한 모델입니다. 초기 비용이나 장기 약정 없이 바로 인스턴스를 시작할 수 있지만, 비용이 가장 높은 옵션입니다. 지속적으로 24/7 운영되는 워크로드에 On-Demand를 사용하면 장기적으로 비용이 크게 누적될 수 있습니다.

- **Reserved 인스턴스 (RI)**: 1년 또는 3년 기간으로 특정 인스턴스 유형에 대한 사용을 선결제(전액 또는 부분 선결제)하거나 약정하여 **최대 72%까지 할인**을 받을 수 있는 옵션입니다 ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=%2A%20Save%20costs%20,and%20save%20up%20to%2020)). 예를 들어 3년 약정으로 표준 RI를 구매하면 동일 인스턴스 On-Demand 대비 50~70% 할인된 시간당 요금이 적용됩니다. Reserved 인스턴스는 가용 영역(AZ) 고정 여부(지역 RI vs 특정 AZ RI), 인스턴스 크기 가변성(Convertible RI는 유형 변경 가능) 등에 따라 유연성이 다릅니다. **Convertible RI**를 사용하면 약정 기간 중에 인스턴스 패밀리나 크기를 변경할 수 있어 워크로드 변경에 대응할 수 있습니다.

- **Savings Plans**: 2019년에 도입된 Savings Plans는 EC2, Fargate, Lambda 사용량에 대해 시간당 일정 금액 지불을 약정하면 유연하게 할인받는 모델입니다. Compute Savings Plan의 경우 인스턴스 유형, 리전 관계없이 약정한 사용량까지 할인된 요금이 적용되어, RI와 유사한 **최대 66~72% 할인 효과**를 얻을 수 있습니다 ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=%2A%20Save%20costs%20,and%20save%20up%20to%2020)). Savings Plans는 특정 인스턴스에 국한되지 않으므로, 예측이 어려운 워크로드나 인스턴스 패턴 변화가 있는 환경에서 선호됩니다. 예를 들어 **AWS Savings Plans를 통해 EC2 비용을 최대 72%까지 절감**할 수 있었던 사례들이 보고됩니다 ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=%2A%20Save%20costs%20,and%20save%20up%20to%2020)). Savings Plans는 구매 시 AWS Cost Explorer의 추천을 참고하여 적정 약정량을 결정하는 것이 좋습니다.

- **권장 적용**: 엔터프라이즈에서는 **기본 워크로드는 Reserved/Savings Plan으로 커버**하고, 변동적인 추가 수요는 On-Demand나 Spot으로 대응하는 패턴이 일반적입니다 ([Auto Scaling groups with multiple instance types and purchase options - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html#:~:text=You%20can%20launch%20and%20automatically,and%20performance%20for%20your%20application)) ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=7,There%20are)). 스타트업의 경우 초기에는 향후 필요 용량을 정확히 알기 어려우므로 **On-Demand로 시작해 모니터링한 후 일정 수준 이상 꾸준한 사용량이 보이면 Savings Plans나 RI를 도입**하는 전략이 유용합니다. 예를 들어 한 **스타트업은 개발/테스트 서버를 업무 시간에만 켜두고 야간에는 자동으로 정지**시켜 70% 이상의 비용을 절감했습니다 ([Stop and start EC2 instances automatically on a schedule using Quick Setup - AWS Systems Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/quick-setup-scheduler.html#:~:text=For%20example%2C%20you%20currently%20might,to%20set%20up%20your%20configuration)). AWS Systems Manager의 **인스턴스 스케줄러**를 이용하면 태그 단위로 인스턴스를 시작/중지하는 일정을 구성하여, 주 5일 8시간만 구동해도 70~75%의 비용 절감 효과를 볼 수 있습니다 ([Stop and start EC2 instances automatically on a schedule using Quick Setup - AWS Systems Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/quick-setup-scheduler.html#:~:text=For%20example%2C%20you%20currently%20might,to%20set%20up%20your%20configuration)) ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=and%20establishing%20processes,from%20increasing%20output%20and%20reducing)).

### Spot 인스턴스 활용

- **Spot 인스턴스 개요**: Spot 인스턴스는 AWS가 남는 용량을 최대 90% 할인된 가격에 제공하는 인스턴스입니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=Spot%20Instances%20let%20you%20take,to%20be%20gracefully%20shut%20down)) ([Spot Instances Explained: How They Can Lower Cloud Costs](https://www.cloudzero.com/blog/spot-instances/#:~:text=According%20to%20Amazon%2C%20EC2%20Spot,Demand%20Instances)). 예를 들어 On-Demand로 시간당 $1 하던 인스턴스를 Spot으로 쓰면 $0.1 수준으로도 이용 가능하다는 뜻입니다. 이렇게 저렴한 대신 **언제든지 (2분 사전 통보 후) 인스턴스가 종료될 수 있는 위험**을 동반합니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=discounts%2C%20AWS%20has%20the%20option,to%20be%20gracefully%20shut%20down)) ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=capacity.%20AWS%20provides%20a%20two,to%20be%20gracefully%20shut%20down)). 따라서 **중단에 대비할 수 있는 워크로드** (예: 웹 서버 팜의 일부, 배치 처리, CI/CD 작업, 빅데이터 분석, HPC 작업 등) ([Auto Scaling groups with multiple instance types and purchase options - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html#:~:text=Spot%20Instances%20are%20spare%20capacity,workloads%2C%20and%20other%20flexible%20workloads))에 적합합니다. 반면 **단일 인스턴스에 상태를 저장하는 DB 서버 등 중단에 민감한 작업에는 Spot을 사용하지 않는 것**이 좋습니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=Spot%20Instances%20can%20be%20used,intolerant%2C%20or%20tightly%20coupled)).

- **비용 절감 효과**: Spot 인스턴스 활용 시 극적인 비용 절감 사례가 많습니다. 예를 들어 미식축구 리그(NFL)는 시즌 일정 생성에 약 **4,000개의 Spot 인스턴스**를 활용하여 시즌당 **$200만 달러를 절감**했습니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=Amazon%20EC2%20Spot%20Instances%20,Instances%20by%20following%20best%20practices)). 뉴스 앱 스마트뉴스(SmartNews)는 **백엔드 주요 워크로드의 70%를 Spot으로 전환**하여 **50% 비용 절감**을 달성했습니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=Solution%20%7C%C2%A0Reducing%20Main,50%20Percent%20Using%20Spot%20Instances)). Spot 인스턴스는 AWS도 권장하는 강력한 절감 수단이며, **“작든 크든 대부분의 조직이 Spot으로 이익을 볼 수 있다”**고 언급될 정도입니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=an%20example%20of%20customer%20using,Spot%20Instances%20by%20following%20best)).

- **최적 활용 및 모범 사례**: Spot 인스턴스를 안정적으로 사용하려면 몇 가지 베스트 프랙틱스를 따라야 합니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=1)) ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=generations%2C%20instance%20types%2C%20and%20Availability,scaling%2C%20resilience%2C%20and%20cost%20optimization)):

  1. **다양한 인스턴스 풀 활용**: 하나의 인스턴스 타입/AZ에만 의존하지 말고, **가능한 여러 인스턴스 타입, 크기, AZ로 분산**하여 요청합니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=the%20same%20instance%20type%20,to%20increase)) ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=generations%2C%20instance%20types%2C%20and%20Availability,scaling%2C%20resilience%2C%20and%20cost%20optimization)). 예를 들어 c5.large만 쓰는 대신 c6a.large, m5.large 등 유사 스펙의 인스턴스를 섞고, us-east-1a뿐 아니라 1b, 1c 등 다중 AZ에 걸쳐 요청하면 Spot이 회수될 위험을 줄이고 확보 가능성을 높입니다. 이를 위해 **Auto Scaling 그룹의 “인스턴스 유형 다변화”** 기능이나 **EC2 Fleet/Spot Fleet**를 사용하면 여러 타입을 한꺼번에 관리할 수 있습니다.
  2. **속성 기반 인스턴스 선택**: 인스턴스 패밀리가 많아 관리가 어렵다면, **속성 기반(instance attribute-based)으로 인스턴스 선택**을 할 수 있습니다. Auto Scaling 그룹에서 vCPU, 메모리, 아키텍처 등의 요구 조건만 지정하면 해당 조건을 만족하는 여러 인스턴스 타입을 자동으로 선택하여 활용할 수 있습니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=We%20have%20established%20that%20flexibility,Moreover%2C%20this)). 이를 통해 신형 인스턴스 출시 시 자동 활용이 가능하며, 수동으로 타입을 나열하는 수고를 덜 수 있습니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=may%20seem%20daunting%20or%20time,based%20instance)).
  3. **Spot 할당 전략 최적화**: Auto Scaling이나 Fleet에서 Spot 인스턴스를 고를 때 **price-capacity-optimized** 등의 전략을 사용하면 가장 용량 여유가 많으면서도 저렴한 풀을 선택합니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=to%20select%20instance%20types,default%20to%20the%20price%20of)). 기본값인 **capacity-optimized** 또는 2023년에 추가된 **price-capacity-optimized** 전략은 Spot 중단 가능성을 낮추는 방향으로 인스턴스를 할당하므로, 가능한 설정을 활용하는 것이 좋습니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=to%20select%20instance%20types,default%20to%20the%20price%20of)).
  4. **Spot 중단 대응**: AWS는 Spot 인스턴스 중단 전에 **2분 전 통보 신호(Instance interruption notice)**를 인스턴스 메타데이터와 EventBridge 이벤트로 제공합니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=discounts%2C%20AWS%20has%20the%20option,to%20be%20gracefully%20shut%20down)) ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=capacity.%20AWS%20provides%20a%20two,to%20be%20gracefully%20shut%20down)). 이 신호를 활용하여 애플리케이션이 **graceful shutdown**을 하거나 대체 작업을 수행하도록 해야 합니다. 예를 들어 **EC2 Auto Scaling의 “수명주기 훅(Lifecycle Hook)”**을 활용하면 인스턴스 종료 직전에 후처리 작업을 트리거할 수 있습니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=2,EC2%20Auto%20Scaling%20lifecycle%20hooks)) ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=,event%20pattern%20matches%20the%20rule)). 사용자는 종료 통보 수신 시 작업을 완료하고 상태를 저장(로그를 S3에 업로드하거나, 작업 중인 큐 메시지를 반환 등)하도록 Lambda 함수를 연계하거나, 인스턴스 내 스크립트를 배치할 수 있습니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=,Amazon%20SQS%20workers)) ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=,lifecycle%20state%20through%20instance%20metadata)). 중요한 것은 해당 작업을 2분 내에 끝내도록 구성하는 것입니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=,lifecycle%20state%20through%20instance%20metadata)).
  5. **Capacity Rebalancing**: Auto Scaling 그룹의 **용량 재균형(Capacity Rebalancing)** 기능을 활성화하면 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=9,These%20add%20guardrails%20to%20your)) Spot 중단 위험이 감지될 때(재균형 권고 신호 수신 시) ASG가 새로운 Spot 인스턴스를 선출범시켜 교체하도록 **자동화**할 수 있습니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=When%20Spot%20Instances%20are%20at,an%20elevated%20risk%20of%20interruption)) ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=Scaling,an%20elevated%20risk%20of%20interruption)). 이를 통해 중단 발생 시까지 기다리지 않고 미리 워크로드를 다른 인스턴스로 옮겨 안정성을 높입니다. 예를 들어, 재균형이 활성화된 ASG에서는 Spot 인스턴스에 위험 신호가 올 경우 대체 인스턴스를 미리 띄우고, 새 인스턴스가 정상 작동하면 기존 인스턴스를 종료시켜 서비스 중단을 피합니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=When%20Spot%20Instances%20are%20at,an%20elevated%20risk%20of%20interruption)) ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=With%20Capacity%20Rebalancing%2C%20Amazon%20EC2,instance%20receives%20a%20rebalance%20recommendation)).

- **Spot 요청 방법 (CLI/SDK)**: Spot 인스턴스를 실무에 적용하려면 AWS 콘솔 또는 CLI, SDK를 활용합니다. 예를 들어 **AWS CLI로 Spot 인스턴스 요청**은 다음과 같이 수행할 수 있습니다.

  ```bash
  # 1. 개별 Spot 인스턴스 요청 (duration없이 단순 요청)
  aws ec2 run-instances --image-id ami-xxxxxxxx \
    --instance-type c5.large \
    --instance-market-options MarketType=spot \
    --key-name MyKeyPair --subnet-id subnet-12345

  # 2. Spot Fleet 요청 (여러 타입/수량을 한꺼번에 요청)
  aws ec2 request-spot-fleet --spot-fleet-request-config file://config.json
  ```

  여기서 `config.json`에는 Spot Fleet에 사용할 인스턴스 유형 목록, 최대 가격, 목표 용량 등이 포함됩니다. Spot Fleet이나 Auto Scaling 그룹을 사용하면 **여러 Spot 인스턴스를 자동 유지**할 수 있어, 개별 수동 관리보다 유리합니다. 특히 Auto Scaling 그룹에 Spot을 적용하면 용량 확보, 교체, 스케일 조정을 AWS가 관리해주므로 효율적입니다.

### Auto Scaling 및 인스턴스 수요 관리

- **오토스케일링을 통한 탄력적 사용**: **AWS Auto Scaling 그룹(ASG)**은 수요에 따라 인스턴스 개수를 자동으로 증감시켜줍니다. 이를 통해 **과소/과대 프로비저닝을 막아 비용 효율화**를 달성합니다. 예를 들어 평균 CPU 사용률이 10%에 불과한 10개의 인스턴스를 가지고 있다면, Auto Scaling을 통해 부하 피크 시를 제외하고는 인스턴스 수를 줄여 놓고 필요 시에만 늘릴 수 있습니다. 실제 사례로, 한 웹 애플리케이션은 Auto Scaling으로 야간에는 인스턴스 2개로 축소하고 주간 트래픽 시에는 최대 10개까지 늘리도록 구성해 약 60%의 비용을 절감했습니다 (내부 사례). Auto Scaling 도입 전후 비용을 비교하면 트래픽 패턴이 불규칙한 워크로드일수록 비용 절감 효과가 큽니다.

- **혼합 인스턴스 정책**: Auto Scaling 그룹은 **혼합 인스턴스 모드**를 지원하여, 일정 비율은 On-Demand로 유지하고 나머지는 Spot으로 충원하는 전략을 쓸 수 있습니다 ([Auto Scaling groups with multiple instance types and purchase options - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html#:~:text=You%20can%20launch%20and%20automatically,and%20performance%20for%20your%20application)). 예를 들어 “On-Demand 기본 용량 2개, 초과분의 50%는 On-Demand, 50%는 Spot”과 같은 비율을 설정할 수 있습니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=7,There%20are)). 아래는 AWS CLI를 통해 **혼합 인스턴스 ASG를 생성**하는 JSON 설정 예시입니다:

  ```json
  "AutoScalingGroupName": "my-mixed-asg",
  "MixedInstancesPolicy": {
      "LaunchTemplate": {
          "LaunchTemplateSpecification": {
              "LaunchTemplateName": "my-template",
              "Version": "$Latest"
          },
          "Overrides": [
              { "InstanceType": "m5.large" },
              { "InstanceType": "m5a.large" },
              { "InstanceType": "c5.large" },
              { "InstanceType": "c5a.large" }
          ]
      },
      "InstancesDistribution": {
          "OnDemandPercentageAboveBaseCapacity": 30,
          "OnDemandBaseCapacity": 1,
          "SpotAllocationStrategy": "capacity-optimized"
      }
  },
  "MinSize": 1,
  "MaxSize": 10,
  "DesiredCapacity": 3,
  "VPCZoneIdentifier": "subnet-aaa,subnet-bbb,subnet-ccc"
  ```

  위 설정에서, 기본용량 1개는 온디맨드로 유지하고, 그 이상 증설되는 용량의 30%는 온디맨드, 70%는 Spot으로 충원하도록 지정했습니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=%7D%2C%20,c934b782)) ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=,c934b782)). 또한 여러 인스턴스 타입(m5, c5 계열 등)을 Override에 나열하여 다양한 Spot 풀을 활용합니다. 이처럼 **Auto Scaling 그룹을 이용해 On-Demand와 Spot을 혼용**하면 안정성과 비용절감을 동시에 얻을 수 있습니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=7,There%20are)). (콘솔에서도 Auto Scaling 그룹 생성 시 “인스턴스 구매 옵션”에서 혼합 모드를 설정할 수 있습니다.)

- **실시간 사용량에 따른 스케일링**: 오토스케일링을 할 때 **스케일 아웃/인 트리거**로 **CloudWatch 지표**를 사용합니다. 일반적으로 **CPU 이용률**이 가장 많이 활용되며, **네트워크 I/O, 요청 수, 큐 길이** 등의 지표도 활용됩니다. 예를 들어 **CPU 사용률 평균이 70%를 5분 이상 초과하면 인스턴스 1대를 추가**하고, **CPU가 20% 미만으로 10분 지속되면 인스턴스 1대를 종료**하는 간단한 정책을 세울 수 있습니다. AWS 콘솔에서 Auto Scaling 정책으로 임계치 기반 조건을 설정하거나, AWS CLI로 **`put-scaling-policy`** 명령을 사용할 수 있습니다.

  - _CLI 예시:_ 아래는 **타겟 추적 방식(Target Tracking)**으로 Auto Scaling 그룹의 **평균 CPU 사용률을 50%로 유지**하도록 하는 설정입니다. 이 정책을 적용하면 ASG가 자동으로 인스턴스 개수를 증감하여 CPU 50% 수준을 타겟팅합니다.

    ```bash
    aws autoscaling put-scaling-policy \
      --policy-name "cpu50-target-tracking" \
      --auto-scaling-group-name MyASG \
      --policy-type TargetTrackingScaling \
      --target-tracking-configuration '{
            "TargetValue": 50.0,
            "PredefinedMetricSpecification": {
                "PredefinedMetricType": "ASGAverageCPUUtilization"
            }
        }'
    ```

    _설명_: `PredefinedMetricType`으로 `ASGAverageCPUUtilization`를 지정하면 Auto Scaling이 그룹 내 인스턴스들의 평균 CPU를 모니터링하여 `TargetValue`에 가깝게 유지합니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=aws%20autoscaling%20put,%7D)). 예를 들어 부하가 늘어 평균 CPU가 80%까지 올라가면 자동으로 인스턴스를 추가해 평균치를 낮추고, 부하가 줄어 평균 20%가 되면 인스턴스를 줄여 비용을 절감합니다.

  - _실무 설정 팁_: 일반적으로 **Target CPU 목표값 50~60%** 선에서 시작하는 것을 권장합니다 ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=target%20a%20steady%20state%20utilization,15)). 50%는 가용 여유를 충분히 두면서도 자원 낭비를 줄이는 보수적인 값입니다. 특히 다중 AZ에 걸쳐 고가용성을 구성했다면, 한 AZ가 내려가도 나머지 AZ의 인스턴스들이 감당하도록 각 인스턴스가 60~70% 이상 과부하되지 않도록 하는 것이 좋습니다 ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=Some%20applications%20might%20have%20very,and%20in%20practice%20even%20less)) ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=target%20a%20steady%20state%20utilization,15)). 예를 들어 3개 AZ에 분산된 서비스라면, **정상 시 한 AZ당 50% 수준으로 운영하여 한 AZ 장애시 전체가 75% 정도로 올라오게 설계**하는 식입니다. 반대로 배치 작업처럼 장시간 스케일링이 어려운 작업(예: 수시간 걸리는 대용량 처리)이라면, 스파이크 대응을 위해 평소 낮은 활용도로 유지해야 할 수도 있습니다 ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=utilization%20in%20theory%2C%20and%20in,practice%20even%20less)). 각 워크로드 특성에 맞게 **스케일 인/아웃 임계값과 cooldown 시간을 튜닝**하는 것이 중요합니다.

  - _메모리 기반 스케일링_: EC2 기본 지표에는 메모리 사용률이 포함되어 있지 않지만, CloudWatch 에이전트를 통해 메모리 사용률 커스텀 지표를 보낼 수 있습니다. 예를 들어 메모리 사용률(`MemoryUtilization`)을 70%로 타겟팅하는 Target Tracking 정책을 만들려면 **`--target-tracking-configuration`**에 `CustomizedMetricSpecification`으로 해당 지표를 명시해야 합니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=%7B%20,Average)). 이를 위해 각 인스턴스에서 일정 간격으로 CloudWatch에 메모리 사용률을 퍼센트로 퍼블리시하고, Auto Scaling 정책에서 해당 지표를 활용하면 됩니다. 다만 구성의 복잡도가 올라가므로, 메모리가 중요하게 쓰이는 애플리케이션의 경우 처음부터 메모리 대비 적절한 인스턴스 타입을 선택하거나, 쿠버네티스 같은 플랫폼 위에서 HPA를 사용할 수도 있습니다.

- **실시간 비용 모니터링**: Auto Scaling을 적용하면 비용이 어떻게 변동하는지 **AWS Cost Explorer나 Budgets**로 모니터링이 필요합니다. 갑작스러운 트래픽 폭주로 인한 과도한 스케일 아웃은 비용 폭증을 야기할 수 있으므로 **상한선(Max Capacity)**을 두고, 예상치 못한 패턴이 나오면 인프라를 재평가해야 합니다. 엔터프라이즈에서는 **FinOps** 툴을 활용해 팀별로 예산 대비 사용량을 점검하기도 합니다 ([](https://arxiv.org/pdf/2501.14753#:~:text=In%20today%E2%80%99s%20fast,Compared%20to%20traditional%20data%20center)) ([](https://arxiv.org/pdf/2501.14753#:~:text=Infrastructure%20as%20a%20Service%20%28IaaS%29,grip%20on%20their%20financial%20management)).

### 서버리스(Lambda, Fargate)와의 비용 비교

EC2를 최적화하는 한편, **AWS Lambda나 Fargate 같은 서버리스**로 전환하면 비용이 절감될 수 있는 시나리오가 있습니다. 서버리스는 **사용한 만큼만 비용 지불(초 단위 청구)**하므로, 트래픽이 들쭉날쭉하거나 **평균 부하가 낮은 서비스**에 적합합니다 ([AWS Lambda vs EC2 Cost Comparison - Trek10](https://www.trek10.com/blog/lambda-cost#:~:text=AWS%20Lambda%20vs%20EC2%20Cost,on%20the%20memory%20and)). 예를 들어 하루에 몇 번만 요청을 받는 웹훅 처리기나, 간헐적으로 배치로 실행되는 작업은 EC2 한 대를 계속 켜두는 것보다 Lambda 함수로 필요 시에만 실행되게 하는 것이 비용 효율적입니다. 반면 **상시 고부하로 돌아가는 서비스**라면 Lambda 비용이 누적되어 EC2보다 비싸질 수 있습니다 ([AWS Lambda vs EC2: Compared on Performance, Cost, Security ...](https://lumigo.io/blog/aws-lambda-vs-ec2/#:~:text=AWS%20Lambda%20vs%20EC2%3A%20Compared,execution%20time%20and%20memory%20requirements)) ([Know how much your EC2 application WILL cost you, in near real ...](https://www.concurrencylabs.com/blog/aws-pricing-lambda-realtime-calculation-function/#:~:text=given%20)).

- **Lambda 비용 평가**: Lambda 함수는 메모리 할당량(MB)과 실행 시간(ms)에 따라 비용이 산정됩니다. 대략적으로 **메모리 512MB로 1초간 실행하면 $0.00001667 정도**의 비용이 발생하므로(100만 회에 약 $16.67 수준), 초당 수백 회 이상 지속 호출되는 워크로드는 EC2가 저렴할 수 있습니다. 커뮤니티에서는 Lambda와 EC2의**비용 교차점(break-even point)**을 계산한 예시들이 있는데, **EC2 t3.small 한대를 계속 켜두는 비용과 동일해지는 호출량을 기준으로 삼기도 합니다** (예: 메모리 512MB Lambda를 완전히 24시간 돌릴 경우 시간당 약 $0.03로 t3.small 여러 대 비용과 맞먹음) ([Why is everyone saying Lambda is more expensive than EC2? : r/aws](https://www.reddit.com/r/aws/comments/13p9sgl/why_is_everyone_saying_lambda_is_more_expensive/#:~:text=r%2Faws%20www,02988%2Fhour)). 따라서**“짧고 드문 작업 = Lambda, 지속적이고 무거운 작업 = EC2”**라는 가이드가 흔히 적용됩니다.

- **Fargate**: AWS Fargate은 컨테이너 기반 서버리스로 EC2 없이 ECS/EKS 작업을 실행합니다. EC2에 비해 단가가 높지만, **컨테이너 인스턴스 운영 비용(유휴 비용)**을 제거할 수 있습니다. 예를 들어 하루에 2시간만 작업하는 배치 컨테이너라면 Fargate로 필요한 2시간만 비용을 내고, EC2로 24시간 돌리는 것보다 훨씬 저렴합니다. 반면 24시간 풀가동하는 컨테이너 서비스는 Fargate보다 EC2(특히 Savings Plan 적용시)가 저렴해지는 구간이 있습니다.

- **비교 적용 사례**: 한 스타트업은 초기에는 Lambda로 백엔드를 구현하여 사용자 수가 적을 때 비용을 절약했고, 서비스가 성장해 **일정 TPS 이상에서 Lambda 비용이 EC2를 추월**하자 컨테이너+EC2로 마이그레이션하여 Reserved 인스턴스로 비용을 통제했습니다 (가상 시나리오). 또 다른 사례로, 이미지 썸네일 생성같이 호출 빈도가 들쭉날쭉한 작업은 EC2보다는 Lambda로 처리해 **월 수십 달러**로 운용했고, 상시 트래픽을 처리하는 websocket 서버는 EC2 Auto Scaling으로 **Reserved 인스턴스**를 활용하여 비용을 낮추면서도 고성능을 보장했습니다.

- **서버리스 대체 판단 기준**: **요청 빈도**, **실행 지속 시간**, **상시 가동 여부**, **운영 관리 비용**을 모두 고려해야 합니다. 서버리스 전환 시 **인프라 관리 비용(패치, OS 관리 등)**이 줄어드는 이점도 있으므로, 인력 리소스 측면의 비용까지 감안해서 판단합니다. 엔터프라이즈 R&D 부서의 실험적 서비스나 이벤트 기반 트리거는 Lambda로 빠르게 구현하고, 핵심 대용량 서비스는 EC2로 최적화하는 **하이브리드 아키텍처**도 흔합니다.

요약하면, **EC2 비용 최적화**는 아래와 같은 **조합 전략**으로 접근해야 합니다:

- _Right-sizing_: 필요한 성능에 맞는 인스턴스 패밀리와 크기 선택 (예: CPU 10% 사용에 m5.large 쓸 바에 t3.small로 다운사이징).
- _Reservation_: 장기간 사용하는 인스턴스는 RI나 Savings Plan으로 할인 확보 ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=%2A%20Save%20costs%20,and%20save%20up%20to%2020)).
- _Spot 활용_: 중단 허용 작업에는 Spot을 최대한 활용 (가능하면 아키텍처를 스테이트리스하게 설계).
- _Auto Scaling_: 수요 기반 인스턴스 증감으로 유휴 시간대 비용 제거.
- _서버리스 전환_: 저사용 또는 이벤트성 워크로드는 Lambda/Fargate로 대체.
- _모니터링 및 반복_: CloudWatch, Cost Explorer, AWS Budgets로 **지속적인 모니터링** 및 **튜닝 반복**. AWS Compute Optimizer나 Trusted Advisor의 **인스턴스 추천**도 주기적으로 확인하여 과대/과소 프로비저닝을 해소합니다.

이러한 최적화 기법을 병행하면 **클라우드 비용을 지속적으로 optimize**하면서도 성능과 안정성을 유지할 수 있습니다.

## 2. ARM64 아키텍처 전환(Graviton) 분석

AWS가 자체 설계한 **Graviton 프로세서(ARM64 아키텍처)** 기반 인스턴스는 **동일 가격 대비 더 높은 성능과 낮은 비용**을 제공하는 것으로 알려져 있습니다. 실제로 AWS Graviton2/3 기반 인스턴스는 x86 대비 **최대 40% 이상의 가격 대비 성능 개선**을 달성하며 ([The Rise of Graviton at AWS and How You Can Save by Switching](https://www.vantage.sh/blog/aws-graviton-vs-intel#:~:text=The%20Rise%20of%20Graviton%20at,maintaining%20or%20even%20improving%20performance)), 온디맨드 가격도 약 **10~20% 저렴**하게 책정되어 있어 비용 최적화에 매력적입니다 ([Graviton processors and cost savings : r/aws - Reddit](https://www.reddit.com/r/aws/comments/1fjr8yw/graviton_processors_and_cost_savings/#:~:text=Graviton%20processors%20and%20cost%20savings,x86%20cheaper%20for%20many%20workloads)). 이에 따라 많은 AWS 고객들이 기존 **AMD/Intel 기반(x86, AMD64)** 인스턴스에서 ARM64로 마이그레이션을 진행하고 있습니다. 여기서는 ARM 전환의 **절차**, **호환성 검증 방법**, **고객 사례 효과**, **주의사항**을 다룹니다.

### Graviton (ARM64) 전환 개요와 효과

- **효과 요약**: AWS에 따르면 Graviton2 기반 인스턴스는 **동일 작업에 대해 20% 이상 비용 절감**을 달성할 수 있다고 합니다 ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=%2A%20Save%20costs%20,and%20save%20up%20to%2020)). 예를 들어 NetApp 테스트에 따르면 x86에서 Graviton2로 마이그레이션 시 **최대 20% 비용 절약**을 확인했다고 합니다 ([AWS Cost Optimizations: Tools, Checklist, and Best Practices](https://bluexp.netapp.com/blog/3-ways-to-save-big-and-10-price-variations-to-know-aws-cvo-blg#:~:text=%2A%20Save%20costs%20,and%20save%20up%20to%2020)). 또한 Graviton3 (최신 세대)는 더 향상된 성능으로 워크로드에 따라 추가 이점을 제공합니다. 교육 기술 기업 Instructure 사례에서는 Graviton3 기반으로 이전하면서 **처리량 30% 증가, 비용 15~20% 절감** 효과를 거두었습니다 ([Scaling Up to 30% While Reducing Costs by 20% Using AWS Graviton3 Processors with Instructure | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/instructure-case-study/#:~:text=Up%20to%2030)). 뉴스 애플리케이션 SmartNews는 **ML 추론 및 피드 서비스**를 Graviton으로 이전해 **ML 워크로드 비용 15% 절감, 지연 시간 68% 감소**를 이루었습니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=the%20criticality%20of%20the%20news%2C,%E2%80%9D)). 이처럼 **비용 절감과 성능 향상이라는 두 마리 토끼**를 잡은 사례들이 늘고 있습니다.

- **지원되는 서비스 및 인스턴스**: 현재 AWS의 많은 인스턴스 패밀리(m6g, c7g, r6g 등)에서 Graviton2/3 기반 옵션을 제공합니다. 예를 들어 기존 c5 (Intel) → c6g (Graviton2), m5 → m6g, 또는 최신 c7g (Graviton3)와 같이 세대 업글이 가능합니다. 또한 **AWS Lambda**나 **Fargate**도 ARM 아키텍처를 지원하므로, 애플리케이션을 재컴파일/재빌드하여 Lambda 환경에서 ARM64 실행으로 전환하면 **한도당 더 많은 동시 실행** 또는 **단위 비용 절감** 효과가 있습니다 (Lambda의 경우 ARM 선택 시 20% 요금 할인).

- **전환 난이도**: AWS에 따르면 **대부분의 애플리케이션은 코드를 수정하지 않고도 Graviton으로 전환 가능**하다고 합니다 ([aws-graviton-getting-started/transition-guide.md at main - GitHub](https://github.com/aws/aws-graviton-getting-started/blob/main/transition-guide.md#:~:text=aws,and%20associated%20Operating%20System)). 특히 Python, Java, Node.js 같은 인터프리터 언어는 동일 소스코드로도 ARM에서 동작합니다. 네이티브 바이너리(Go, C/C++ 등)는 재컴파일이 필요하지만 많은 런타임/라이브러리가 ARM 빌드를 제공하고 있습니다. Docker 컨테이너 사용 시 **멀티 아키텍처 이미지**를 구축하면 하나의 이미지로 x86과 ARM을 모두 지원할 수 있습니다. AWS ECR과 Docker Hub는 ARM 이미지를 태그로 구분하거나 manifest 목록으로 멀티-플랫폼 이미지를 지원합니다 ([Migrating Containers to AWS Graviton](https://aws.amazon.com/awstv/watch/1cb0eb0a589/#:~:text=Learn%20how%20to%20migrate%20containerized,better%20performance%20and%20lower%20costs)).

### 전환 절차 및 호환성 체크 방법

1. **사전 호환성 분석**: 현업에서 사용하는 OS, 미들웨어, 언어 런타임, 라이브러리가 ARM64를 지원하는지 조사합니다. 예를 들어:

   - 운영체제: Amazon Linux 2, Amazon Linux 2023, Ubuntu, Red Hat 등 대부분 ARM64 AMI를 제공합니다. Windows Server의 경우 Graviton을 지원하지 않으므로 Windows 워크로드는 전환 불가(이 경우 비용 최적화는 다른 방법 모색).
   - 데이터베이스: Aurora, RDS PostgreSQL 등 AWS 관리형은 내부적으로 ARM 인스턴스를 활용하기도 하지만, 사용자 관리 DB를 EC2에 설치했다면 해당 DB 소프트웨어가 ARM 호환 빌드가 있는지 확인해야 합니다.
   - 언어/프레임워크: Java (OpenJDK는 ARM JIT 지원), Python (동일 코드 사용), .NET Core(ARM64 지원), Node.js(ARM 지원) 등 대부분 문제 없습니다. 단, 특정 C++로 작성된 라이브러리(Python 패키지의 C Extensions 등)는 ARM용 휠이 있는지 확인해야 합니다. 호환성 이슈는 **애플리케이션을 도커 이미지로 패키징**하여 ARM EC2에서 실행해보거나, **AWS Graviton 제공하는 개발자 테스트 환경**(EC2)에서 직접 빌드/테스트함으로써 조기에 발견할 수 있습니다.
   - **AWS 호환 도구**: AWS는 Graviton 호환성 체크를 돕는 **Graviton Ready 프로그램**과 **Graviton Challenge**를 통해 가이드와 툴을 제공합니다. 예를 들어 **AWS Compute Optimizer**는 현재 EC2 인스턴스의 CPU 아키텍처를 분석해 **Graviton 전환 시 이점이 예상되는 리소스**를 추천해주기도 합니다 (예: 동일 성능에 더 저렴한 인스턴스 타입 제안).

2. **테스트 및 빌드**: 새로운 ARM64 환경에서 애플리케이션을 테스트합니다. 절차는 다음과 같습니다:

   - **ARM64 EC2 인스턴스 기동**: 기존 x86 인스턴스와 최대한 유사한 스펙의 Graviton 인스턴스를 하나 띄웁니다. 예를 들어 m5.large(x86, 2vCPU) → m6g.large(ARM, 2vCPU)로 선택하고 Amazon Linux 2 ARM AMI를 사용합니다. AWS CLI로 AMI 목록을 검색할 때 `--owners amazon --filters "Name=name,Values=*ubuntu*arm64*"` 등으로 ARM 이미지를 찾을 수 있습니다. 또는 AWS 콘솔 EC2 런치 시 플랫폼에서 **ARM64**를 선택합니다.
   - **종속 패키지 설치**: 새 인스턴스에서 애플리케이션 구동에 필요한 패키지나 라이브러리를 설치합니다. `yum`이나 `apt`를 통해 설치 시 자동으로 ARM용 바이너리가 받아집니다. 예를 들어 Nginx, MySQL 등 대부분 패키지가 멀티 아키텍처로 제공되므로 동일 명령어로 설치 가능합니다. Docker를 사용한다면 `docker buildx`를 활용해 `--platform linux/arm64`로 이미지를 빌드합니다.
   - **데이터 호환성**: 엔디안 차이나 부동소수점 표현 등 대부분의 현대 아키텍처 간에는 투명하지만, 혹시 ARM/x86 사이에 바이너리 데이터 교환이 있다면 검증이 필요합니다. 일반적인 웹 서비스라면 문제없지만, 메모리 맵 파일을 공유한다거나 저수준 시리얼라이제이션이 있다면 확인합니다.
   - **성능 테스트**: 동일 부하를 주어 응답 시간, 처리량을 측정합니다. 보통 Graviton2/3가 **SPECint 등 벤치마크에서 우수**하다고 하지만, 실제 워크로드로 측정하여 톤 조정을 합니다. 경우에 따라 ARM이 x86보다 빠르므로 인스턴스 사이즈를 한 단계 낮춰도 되는 경우도 있고, 반대의 경우도 드물게 있을 수 있습니다.

3. **이중 배포 및 전환**: 서비스 중단을 피하기 위해 **블루/그린 배포** 전략으로 ARM 전환을 진행합니다. 예를 들어 Auto Scaling 그룹을 복제하여 새 Launch Template에 ARM 인스턴스 타입을 지정하고, 신규 ARM 인스턴스 군을 가동합니다. 그런 다음 트래픽을 서서히 ARM 서버로 늘려가며 (예: ELB 대상 그룹에 ARM 인스턴스를 등록) 문제 없으면 점진적으로 x86 인스턴스를 제거합니다. 이 과정에서 모니터링을 강화하여 에러율, Latency 등을 비교합니다.

4. **완료 및 비용 검증**: ARM 전환이 완료되면 CloudWatch 지표로 **CPU 사용률이 낮아졌는지**, 처리량은 같거나 증가했는지 살펴보고, Cost Explorer를 통해 시간당 비용이 감소했는지 확인합니다. Graviton은 **vCPU당 가격이 저렴**하므로 동일 vCPU수로 구성하면 바로 비용 감소를 볼 수 있습니다. 혹은 성능 향상으로 **인스턴스 수 자체를 줄였다면** 더 큰 비용 절감이 실현됩니다. SmartNews의 경우 ARM 전환 후 **60~70%의 워크로드를 Graviton으로 돌리면서 성능도 개선되어** 인스턴스 수를 줄일 여력이 생겼습니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=the%20criticality%20of%20the%20news%2C,%E2%80%9D)).

### 실제 사례: ARM64 전환 효과

- **스마트뉴스(SmartNews)**: 앞서 언급했듯 컨테이너 기반 뉴스 서비스인 스마트뉴스는 2024년에 **Kubernetes 노드 그룹을 Graviton으로 마이그레이션**했습니다. **주요 동기**는 비용 절감이었지만, 부수적으로 **성능 향상**을 얻었습니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=The%20prime%20motivation%20for%20using,%E2%80%9D)). 핵심 ML 추론 워크로드를 ARM으로 옮겨 **15% 비용 절감**과 함께 **레이턴시 190ms -> 60ms 단축(약 68% 개선)**을 달성했습니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=the%20criticality%20of%20the%20news%2C,%E2%80%9D)). 또한 **Spot 인스턴스 70% 활용 전략**과 결합하여 전체 인프라 비용을 크게 낮추었습니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=Solution%20%7C%C2%A0Reducing%20Main,50%20Percent%20Using%20Spot%20Instances)). 이는 **엔터프라이즈** 사례로, AWS 전문가들과 협업하며 코드 수준 튜닝도 병행한 결과입니다 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=and%20it%20worked%20alongside%20specialist,managed%20to%20lower%20its%20costs)).

- **Instructure**: Canvas LMS로 유명한 교육 플랫폼 Instructure는 COVID-19 이후 폭증한 온라인 트래픽을 감당하기 위해 Graviton3 인스턴스로 전환했습니다. 그 결과 **응답시간이 1.5초 -> 0.5초로 줄고, 오류율 감소, 처리량 30% 증가** 등의 성능 개선과 **15~20% 비용 절감**을 함께 이뤘습니다 ([Scaling Up to 30% While Reducing Costs by 20% Using AWS Graviton3 Processors with Instructure | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/instructure-case-study/#:~:text=Up%20to%2030)). 특히 **피크 시 수천 대의 EC2를 운영**하는 대규모 환경에서 연간 수백만 달러의 비용을 아낀 것으로 알려졌습니다 (대략적인 추산). 이 사례는 **대기업/엔터프라이즈**에서 Graviton으로 **효율성과 비용 두 마리 토끼**를 잡은 예입니다.

- **GE Vernova**: (발전 산업 분야) GE Vernova는 HPC 성격의 워크로드를 Graviton2 기반으로 이전하여 **컴퓨팅 성능을 향상시키면서 $100만 이상의 비용을 절감**했다는 사례가 있습니다. 이는 주로 **고성능 데이터 처리 작업**에서 ARM 아키텍처의 장점을 살린 경우입니다. GE Vernova는 이전 과정에서 인스턴스 사이즈를 조정(right-sizing)하고 ARM 최적 컴파일을 적용하여 **성능당 비용을 크게 낮추는** 최적화를 이루었습니다.

- **기타**: Capital One 등의 금융권에서도 **Graviton 도입으로 수백만 달러 절감**과 탄소발자국 감소 효과를 봤다고 발표했습니다 (출처: AWS re:Invent 2022 세션). **스타트업의 경우**도, 초기에는 x86으로 개발했다가 **클라우드 비용이 커지는 시점에 ARM으로 리프트앤시프트**하여 월 사용료를 20~30% 줄이고 그 재원을 R&D에 재투자하는 사례가 있습니다.

### ARM64 전환 시 고려사항 (주의점)

- **소프트웨어 호환성**: 대부분 양호하지만, **일부 상용 소프트웨어가 ARM을 지원하지 않을 수 있음**에 유의해야 합니다. 예를 들어 상용 APM 에이전트, 보안 에이전트 등이 x86 전용일 수 있습니다. 이 경우 해당 벤더의 지원 로드맵을 확인하거나 대안을 찾아야 합니다.

- **연산 성능 차이**: ARM은 부동소수점 연산 등에서 x86과 미세한 성능 차이가 있을 수 있습니다. 암호화, 머신러닝 추론 등 일부 워크로드는 Graviton 전용 최적화 라이브러리(AWS Neuron SDK 등)를 사용해야 최대 성능이 납니다. 일반적으로는 큰 문제 없지만, **특정 워크로드(예: AVX512 최적화 코드)**는 x86 전용이므로 ARM에서 대체 명령셋(NEON)이 성능이 살짝 낮을 수 있습니다.

- **툴링과 CI/CD**: ARM으로의 전환은 **CI/CD 파이프라인**에도 영향을 줍니다. CI 서버에서 ARM용 바이너리를 빌드하려면 도커 멀티아키 빌드, cross-compile 설정이 필요합니다. AWS CodeBuild는 ARM 환경을 제공하므로 이를 활용하거나, GitHub Actions 등에서 QEMU를 써서 ARM 에뮬레이션 빌드가 가능합니다 ([[PDF] Migrating to AWS Graviton with AWS container services](https://d1.awsstatic.com/events/Summits/reinvent2023/CMP404_Migrating-to-AWS-Graviton-with-AWS-container-services.pdf#:~:text=,generation)). 테스트 단계에서 ARM 환경을 포함하도록 파이프라인을 업데이트해야 합니다.

- **가격 모델**: Graviton 인스턴스도 RI, Savings Plan, Spot 모두 지원하므로 동일하게 최적화 가능합니다. 다만 **시장의 Spot 용량 상황**은 인스턴스 타입별로 다르므로, 처음 ARM 전환 시에는 On-Demand로 안정성 테스트를 하고 이후에 Spot 활용을 고려합니다. (초창기에는 Graviton 인스턴스가 Spot에 잘 안 풀리기도 했으나, 현재는 많이 안정되었습니다.)

- **지원 커뮤니티**: ARM 관련 이슈는 AWS Graviton 공식 포럼이나 오픈소스 커뮤니티를 통해 지원을 받는 것이 좋습니다. 예를 들어 Reddit의 r/aws에서 “Graviton 사용시 문제점”에 관한 토론에서, **“실질적 단점은 거의 없으며 오히려 대부분의 경우 이점만 있었다”**는 경험담이 공유되기도 했습니다 ([Any downsides of using AWS Graviton based compute - Reddit](https://www.reddit.com/r/aws/comments/13mig8k/any_downsides_of_using_aws_graviton_based_compute/#:~:text=Any%20downsides%20of%20using%20AWS,to%20architecture%20for%20compute%20services)).

결론적으로, **ARM64(Graviton)으로의 전환**은 현재 클라우드 비용 최적화의 강력한 트렌드입니다. 호환성만 확보되면 **적은 변경으로 큰 비용 절감 효과**를 볼 수 있으며, AWS도 **Graviton으로의 전환을 적극 장려**하고 있습니다. 이를 위해 전환 가이드 ([AWS EC2 Graviton Getting Started Step-by-Step Guide - Amazon.com](https://aws.amazon.com/ec2/graviton/getting-started/#:~:text=Amazon,based%20EC2%20instances%20with%20ease))와 툴을 제공하고 있으므로, 단계적으로 테스트를 거쳐 적용하면 됩니다.

## 3. On-Demand → Spot 인스턴스 전환 자동화 방법

앞서 Spot 인스턴스의 이점을 살펴봤는데, 기존에 **On-Demand로 운용 중인 워크로드를 어떻게 자동으로 Spot으로 전환**할 수 있을지 구체적인 방법을 알아보겠습니다. Spot은 비용은 낮지만 가용성이 가변적이므로, **자동화 도구와 전략**을 통해 안정성을 최대한 확보하면서 전환하는 것이 중요합니다. 주요 방법으로 **Auto Scaling 그룹 활용**, **EC2 Fleet/Spot Fleet 활용**, **Lambda를 이용한 이벤트 기반 전환** 등이 있습니다.

### Auto Scaling 그룹을 통한 점진적 전환

이미 **On-Demand EC2 인스턴스가 한 대 또는 다수 운영 중**이라면, **Auto Scaling 그룹(ASG)**으로 이를 재구성하여 **Spot 인스턴스를 포함**시키는 방법이 가장 많이 쓰입니다. 예를 들어 단일 EC2로 운영되던 웹서버를 동일한 AMI와 사용자 데이터로 Auto Scaling 그룹을 만들고, 최소 용량 1 (On-Demand), 최대 용량 2 이상으로 설정한 후 **여유분을 Spot으로 추가**하게 할 수 있습니다. 이렇게 하면 초기 한 대는 온디맨드로 남아 있고, Auto Scaling이 두 번째 인스턴스를 Spot으로 띄워 로드분산에 추가합니다. 문제없이 동작하면 온디맨드 인스턴스를 점진적으로 축소(예: 기본용량 0으로 수정)하여 모든 인스턴스가 Spot이 되도록 전환할 수 있습니다.

- **1) Auto Scaling 혼합 모드 구성**: 앞서 소개한 **혼합 인스턴스 정책**을 사용합니다. AWS 콘솔에서 기존 Auto Scaling 그룹의 **편집(Edit)** 버튼을 눌러 **“Instance purchase options”** 섹션을 Spot/On-Demand 혼용으로 변경할 수 있습니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=If%20you%20have%20an%20existing,8)). 여기서 *On-Demand base capacity*와 *On-Demand percentage above base*를 조절하여 원하는 Spot 비율을 지정합니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=7,There%20are)). 예를 들어 **기본 1개 온디맨드, 초과분 0% 온디맨드 = 전부 Spot**으로 설정하면, 기존 인스턴스 1개를 제외한 증설분이 모두 Spot으로 나갑니다. Capacity Rebalance를 활성화하여 Spot 안정성을 높이는 것도 잊지 말아야 합니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=9,These%20add%20guardrails%20to%20your)). 이러한 설정을 CLI로 하려면 위에서 소개한 JSON을 사용하거나 `aws autoscaling update-auto-scaling-group` 명령어에 파라미터로 전달합니다 ([Launch Spot Instances with AWS EC2 Auto Scaling Group](https://www.blinkops.com/blog/how-to-launch-spot-instances-with-your-aws-ec2-auto-scaling-group#:~:text=If%20you%20want%20to%20update,group%20command)).

- **2) 배포 방식**: On-Demand → Spot 전환 시 **일시적으로 이중 리소스**가 필요할 수 있습니다. 예를 들어, 5대 온디맨드로 돌고 있는 서비스라면 ASG 설정을 변경하여 Desired 5, Min 0, Max 10, 그리고 “온디맨드 기본 0, 온디맨드 퍼센트 0”으로 하면 ASG는 즉시 Spot 인스턴스 5대를 신규로 띄우고, 기존 5대를 점진적으로 교체하게 됩니다. 이 교체과정을 **Instance Refresh** 기능으로 관리할 수도 있습니다 (새 Launch Template에 Spot 지정 후 Refresh 수행). Instance Refresh를 사용하면 일정 비율씩 (예: 1개씩) 기존 인스턴스를 새 구성(Spot)으로 바꿔주므로 무중단 전환이 가능합니다.

- **3) EC2 Fleet / Spot Fleet 활용**: Auto Scaling 외에 **EC2 Spot Fleet**을 쓰는 방법도 있습니다. Spot Fleet는 **여러 인스턴스 요청을 한꺼번에 관리**해주며, 온디맨드 백업 용량도 설정 가능합니다. 예를 들어 아래는 Spot Fleet 설정의 일부입니다:

  ```json
  "SpotFleetRequestConfig": {
    "TargetCapacity": 4,
    "OnDemandTargetCapacity": 1,
    "SpotMaintenanceStrategies": {
        "CapacityRebalance": { "ReplacementStrategy": "launch" }
    },
    "LaunchSpecifications": [
        { "InstanceType": "m5.large", "ImageId": "ami-xyz", ... },
        { "InstanceType": "m5a.large", "ImageId": "ami-xyz", ... }
    ]
  }
  ```

  여기서 `OnDemandTargetCapacity`를 1로 두면 4개 중 1개는 온디맨드로 확보하고 나머지 3개는 Spot으로 요청합니다. Spot Fleet도 Auto Scaling과 유사하게 **Capacity Rebalancing**을 지원하여 Spot 중단 시 대체 인스턴스 런치 전략을 설정할 수 있습니다 ([Use Capacity Rebalancing in EC2 Fleet and Spot Fleet to replace at ...](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-fleet-capacity-rebalance.html#:~:text=Use%20Capacity%20Rebalancing%20in%20EC2,Instances%20at%20risk%20of%20interruption)) ([The Ultimate Guide to EC2 Spot Instances | CloudBolt Software](https://www.cloudbolt.io/guide-to-aws-cost-optimization/ec2-spot-instances/#:~:text=Software%20www,a%20running%20Spot%20instance)). Spot Fleet은 주로 **고정된 용량의 배치 작업** 등에 쓰이고, 웹서비스 등에는 Auto Scaling이 더 적합합니다. 그러나 Spot Fleet + Elastic Load Balancer로도 충분히 서비스 운영이 가능합니다.

- **4) Lambda를 이용한 커스텀 자동화**: AWS에서 기본 제공하는 기능 외에, 사용자가 Lambda 함수를 이용해 **온디맨드 → Spot 교체를 자동화**할 수도 있습니다. 예를 들어 특정 태그를 가진 EC2 인스턴스들을 감시하다가, 새 Spot 인스턴스를 확보하면 기존 온디맨드 인스턴스를 내려주는 Lambda를 짤 수 있습니다. EventBridge 스케줄러나 AWS Config Rule로 **주기적으로 EC2 상태를 체크**하면서, 온디맨드 인스턴스가 일정 시간 이상 유지되면 동일한 AMI로 Spot 인스턴스 띄워 ELB에 붙이고, 성공하면 온디맨드를 내리는 식입니다. 다만 이러한 커스텀 방식은 **구현 복잡도와 잠재 버그**를 동반하므로, 가능하면 AWS가 제공하는 Auto Scaling MixedInstancesPolicy나 Spot Fleet에 의존하는 것이 좋습니다.

### Spot 운영 시 장애 대비 및 데이터 보존 전략

Spot 인스턴스 전환 자동화에서 가장 중요한 것은 **장애 시 영향 최소화**입니다. Spot 인스턴스는 예고 후 종료되지만, 짧은 시간 내 대체가 이뤄지지 않으면 서비스에 영향이 있을 수 있습니다. 따라서 아래와 같은 대비책이 필수입니다:

- **데이터/세션 외부화**: 인스턴스 로컬에 중요한 데이터를 저장하지 않고, **EBS, EFS, S3, ElastiCache** 등에 외부화합니다. 예를 들어 웹 서버 세션은 ElastiCache나 DynamoDB를 쓰고, 애플리케이션 로그는 CloudWatch Logs로 스트리밍하거나 주기적으로 S3에 업로드합니다. 이렇게 하면 Spot 인스턴스가 갑자기 교체되어도 **애플리케이션 상태**가 보존됩니다. 만약 어쩔 수 없이 로컬에 저장한다면, **스팟 종료 통보 수신 후 shutdown 스크립트**에서 EBS 볼륨을 분리(detach)하거나 스냅샷 뜨는 작업을 넣을 수 있습니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=2,EC2%20Auto%20Scaling%20lifecycle%20hooks)) ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=,Amazon%20S3)).

- **중단 통보 활용**: 앞서 언급한 **2분 전 통보**는 귀중한 시간입니다. Amazon EventBridge 규칙을 만들면 _EC2 Spot Instance Interruption Warning_ 이벤트를 받아 SNS로 알림을 보내거나 Lambda를 호출할 수 있습니다. 이를 통해 중앙에서 Spot 종료 이벤트를 로깅하고, 필요시 수동介入할 수 있습니다. 또한 각 인스턴스에서는 메타데이터 URL <http://169.254.169.254/latest/meta-data/spot/instance-action> 를 주기적으로 폴링하여 종료 2분 전에 어떤 액션이 예정되어 있는지 확인할 수 있습니다. 이 방식을 통해 애플리케이션 프로세스에게 안전 종료 신호를 보내거나, 나머지 작업을 다른 노드로 이양하는 로직을 구현합니다.

- **Auto Scaling 헬스 체크**: Auto Scaling 그룹을 사용 중이라면 **ELB 연동 건강 체크**나 **EC2 상태 체크**로 Spot 종료를 감지합니다. Spot이 종료되면 인스턴스 상태가 Terminated로 바뀌고, Auto Scaling은 이를 감지해 곧바로 새로운 인스턴스를 띄웁니다. 가능하면 **다중 AZ에 걸쳐 ASG를 구성**하여 한 AZ에 Spot 공급이 줄어도 다른 AZ에서 대체하도록 합니다 ([Capacity Rebalancing in Auto Scaling to replace at-risk Spot Instances - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-capacity-rebalancing.html#:~:text=To%20use%20Capacity%20Rebalancing%20with,group%2C%20the%20basic%20steps%20are)).

- **재시도 로직**: Spot 요청이 일시적으로 용량 부족 등으로 실패할 수 있습니다. 이때를 대비해 **백업 플랜**이 필요합니다. Auto Scaling의 경우 Spot 할당이 실패하면 자동으로 재시도하지만, 오래 지속되면 부족 용량을 온디맨드로 채울 수 있습니다 (예: 일정 시간 내 Spot 못 구하면 온디맨드 늘리도록 수동介入 또는 스케줄 기반 조정). Spot Fleet의 경우 **할당 실패 시 On-Demand 추가옵션**이나 최대 가격 상향 등을 고려해야 합니다.

- **워크로드 특성 고려**: 만약 워크로드가 일시 중단되면 안되는 경우(예: 실시간 처리)에는, Spot으로 옮긴 후에도 **일부 온디맨드 인스턴스를 예비로 유지**하는 전략이 필요합니다. 예를 들어 10대 중 2대는 온디맨드 (20%)로 남겨 두어 Spot 풀 불안시에도 완전 정지는 피하는 식입니다. 앞서 SmartNews 사례에서도 **30%는 온디맨드/RI, 70%는 Spot**으로 섞어서 운용했듯이 ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=Japan%20and%20US%20time%20zones,30%20percent%20other%20payment%20plans)), 비지니스 크리티컬 서비스는 하이브리드로 가는 것이 현실적입니다.

- **테스트**: Spot 전환 자동화 후에는 **장애 시나리오 테스트(Chaos Engineering)**를 수행합니다. AWS Fault Injection Simulator를 활용하면 Spot 인스턴스 중단을 시뮬레이션할 수 있습니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=To%20get%20hands,video%20and%20AWS%20FIS%20documentation)). 예를 들어 일부러 Spot 인스턴스를 종료하는 이벤트를 넣어보고, 시스템이 정상 복구되는지 (새 인스턴스 투입, 세션 복구 등) 점검합니다. 이를 통해 자동화 시나리오에서 빠진 부분이 없는지 확인할 수 있습니다.

정리하면, **온디맨드→Spot 자동화**는:

- 기술적으로 **Auto Scaling Mixed Instances 또는 Spot Fleet** 사용이 권장되며,
- 운영적으로 **중단 대비책(데이터 외부화, 2분 알림 처리)**을 철저히 해야 합니다.

실제 이 패턴을 도입한 스타트업의 예로, 한 기업은 비즈니스 로직 서버 100%를 Spot으로 전환하면서도, 세션 스토리지를 외부화하고 5분 내 재시작 전략을 준비하여 **매월 60% 이상의 EC2 비용 절감을 달성**했습니다 (출처: AWS 사용자 모임 발표, 2023). 엔터프라이즈의 경우에도 R&D나 테스트 클러스터에 Spot을 우선 도입해 안정성을 검증한 후, 프로덕션에도 점진 도입하여 안전하게 비용을 절감하고 있습니다.

## 4. 사용량 기반 오토 스케일링 구현

AWS Auto Scaling을 활용하여 **실제 리소스 사용량(CPU, 메모리 등)에 따라 EC2 인스턴스 수를 자동 조정**하는 것은 클라우드 비용 최적화와 가용성 확보의 핵심입니다. 앞서 부분적으로 다룬 내용을 정리하고, **구체적인 구현 방법과 실무 최적 설정 값**을 논의합니다.

### CloudWatch 지표 기반 Auto Scaling 정책

**오토 스케일링의 기본 개념**: 사용자가 정의한 **스케일링 정책(Scaling Policy)**에 따라 Auto Scaling 그룹의 Desired Capacity를 조절하는 것입니다. 스케일링 정책은 **동적 스케일링**과 **예측/스케줄 기반 스케일링**으로 나뉩니다:

- _동적 스케일링_: CloudWatch 지표에 연동되어 실시간으로 증감 (예: CPU 70% 초과 → +1 인스턴스).
- _예측 스케일링/스케줄_: 일정이나 과거 추세에 따라 증감 (예: 매일 9시 증설, 18시 축소 또는 머신러닝 기반 예측).

여기서는 **동적 스케일링**에 집중합니다.

1. **타겟 추적 방식(Target Tracking Scaling)**: 설정한 목표 지표값을 Auto Scaling 그룹이 자동으로 추적하게 합니다. AWS에서 **권장하는 방식**으로, 설정이 간단하고 스케일 인/아웃 임계값을 일일이 정할 필요가 없습니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=Example%201%3A%20To%20apply%20a,with%20a%20predefined%20metric%20specification)). 예를 들어 **평균 CPU 50%**를 타겟으로 하면, Auto Scaling이 알아서 인스턴스 수를 늘이거나 줄여 CPU 사용률을 50% 부근으로 유지합니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=aws%20autoscaling%20put,%7D)). 위의 CLI 예시처럼 `PredefinedMetricType`에 `ASGAverageCPUUtilization`와 TargetValue를 주면 됩니다. 또는 콘솔에서 Auto Scaling 그룹 > Scaling Policies > Add policy > Target Tracking 선택 후 “Average CPU = 50%” 입력으로 설정합니다.

   - **장점**: 쉬운 설정, CloudWatch Alarm 따로 만들 필요 없음, AWS가 내부 알고리즘으로 적절한 증감폭 결정.
   - **주의점**: 너무 낮은 Target을 지정하면 계속 과소 프로비저닝되어 인스턴스가 최대치로 늘어나거나 성능 저하가 올 수 있고, 너무 높은 Target은 스케일 아웃이 늦어질 수 있습니다. 일반 웹서비스는 40~60% 사이가 적당하며, 50%부터 시작해 조정합니다 ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=target%20a%20steady%20state%20utilization,15)). 또한 기본적으로 **단계적 증감**이 이루어지므로, 급격한 변화에는 대응이 느릴 수 있습니다. 이를 보완하려면 **캡 값**을 설정하여 (예: max 100개) 과도 스케일아웃 방지, 또는 필요 시 기본 용량 (예: 최소 2대)으로 베이스라인을 둡니다.

2. **단계적/단순 조건 방식(Step or Simple Scaling)**: CloudWatch 경보(Alarm)를 활용해 임계치 조건을 직접 지정하는 방법입니다. 예를 들어 “CPU > 70% 5분 지속” Alarm이 발생하면 +2 인스턴스 추가, “CPU < 30% 10분 지속”이면 -1 인스턴스 제거 같은 식으로 **세밀한 제어**가 가능합니다. AWS CLI의 `put-scaling-policy`로 `--policy-type StepScaling`을 지정하고 증감 단계를 정의합니다.

   - _예시_: 아래는 **단계적 스케일 아웃** 정책의 CLI 예시입니다:

     ```bash
     aws autoscaling put-scaling-policy \
       --auto-scaling-group-name my-asg \
       --policy-name cpu70-add2-step \
       --policy-type StepScaling \
       --adjustment-type ChangeInCapacity \
       --metric-aggregation-type Average \
       --step-adjustments '[{"MetricIntervalLowerBound": 0, "ScalingAdjustment": 2}]'
     ```

     그리고 이 정책을 트리거할 CloudWatch Alarm은 별도로 만들어야 합니다:

     ```bash
     aws cloudwatch put-metric-alarm \
       --alarm-name "CPUHighAlarm" \
       --metric-name CPUUtilization --namespace AWS/EC2 \
       --statistic Average --period 300 --threshold 70 \
       --comparison-operator GreaterThanThreshold --evaluation-periods 2 \
       --dimensions "Name=AutoScalingGroupName,Value=my-asg" \
       --alarm-actions arn:aws:autoscaling:...:policy/cpu70-add2-step
     ```

     위 설정은 5분 평균 CPU 70% 초과 시 Alarm 발생 (2회 연속 시), 연결된 autoscaling policy (cpu70-add2-step)가 실행되어 인스턴스 2대를 추가합니다. 스케일 인도 유사하게 설정합니다.

   - **장점**: 복잡한 시나리오 대응 가능 (예: 70% 초과 1대 추가, 85% 초과시 추가로 2대 더 추가 등 여러 Step 정의). **빠른 대응**: Alarm 평가period 등을 1분 단위로 낮추면 거의 실시간에 가깝게 반응.
   - **단점**: 정책 설정과 Alarm 튜닝이 어려움. 잘못하면 **불안정한 플래핑**이 발생할 수 있습니다 (추가 -> 금방 내려가고 반복). 이를 막기 위해 **Cooldown(Time)**이나 **Instance Warmup** 설정이 필요합니다. 예를 들어 scale-out 후 **몇 분간은 scale-in하지 않도록** 하는 쿨다운을 줘야 인스턴스가 완전히 기동되어 부하를 분산할 시간을 확보합니다.

3. **메모리 등 커스텀 지표 사용**: CPU 외에 **메모리 사용률** 등을 지표로 쓰려면, CloudWatch에 해당 메트릭을 퍼블리시하고 Target Tracking의 `CustomizedMetricSpecification`으로 사용하거나, Alarm을 연동해야 합니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=%7B%20,Average)). AWS에서 제공하는 SSM 에이전트를 설치하면 메모리, 디스크 지표를 주기적으로 CloudWatch에 올릴 수 있습니다. 그 후 Auto Scaling에서 MetricName을 "MemoryUtilization", Namespace를 "CWAgent" (또는 사용자 네임스페이스)로 하여 적용합니다. 이때 Metric의 단위를 일치시키고 (퍼센트) 통계값도 평균을 쓰도록 맞춰야 합니다.

4. **네트워크/응답량 기반**: 웹서비스의 경우 **ALB의 RequestCountPerTarget**, **TargetResponseTime** 등을 지표로 쓸 수 있습니다. 예를 들어 “Target 그룹당 초당 1000 요청”을 목표로 하는 타겟 추적 정책을 만들면, 요청이 늘면 자동 증설합니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=aws%20autoscaling%20put,ALBRequestCountPerTarget)). 이 때 `ResourceLabel`에 대상 ALB와 TG 식별자를 넣어야 합니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=,true)). 또는 SQS 소비자 그룹이라면 **SQS 큐의 메시지 적체량**을 커스텀 메트릭으로 환산 (예: 메시지 수/인스턴스 수)하여 타겟 추적하는 방법도 있습니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=aws%20autoscaling%20put,MyNamespace)). 이러한 **도메인 특화 지표**가 실제 부하를 더 정확히 반영할 때도 많습니다.

### 최적 스케일링 설정 (실무 팁)

- **인스턴스 초기 구동 시간 고려**: 새 인스턴스가 **완전히 서비스 가능해질 때까지의 시간**(OS 부팅, 앱 초기화)을 *Instance Warmup*으로 설정하세요. 예를 들어 60초로 지정하면, Auto Scaling은 새로 추가된 인스턴스가 60초 동안은 충분히 기여하지 못할 거라 가정하여 그동안 과도한 스케일아웃을 방지합니다 ([Set the default instance warmup for an Auto Scaling group](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-default-instance-warmup.html#:~:text=Set%20the%20default%20instance%20warmup,and%20cost%20efficiency%20through)).

- **Scale-In 관대하게**: 스케일 인(축소)은 성능에 직접 영향 주므로 보수적으로 합니다. 예를 들어 **Scale-Out** 조건은 CPU > 70% 2분, **Scale-In**은 CPU < 30% 15분 이런 식으로 **충분한 기간**을 둡니다. 또는 **DisableScaleIn** 옵션을 타겟 추적 정책에 적용해 (별도 Scale-In 정책만 존재하도록) 수동으로 줄이는 것도 방법입니다 ([Example scaling policies for the AWS CLI - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/examples-scaling-policies.html#:~:text=,true)). AWS는 기본적으로 Target Tracking에 **알고리즘적 히스테리시스**를 가지고 있어 갑작스런 하락에 바로 줄이지는 않지만, 수동 설정시 실수로 과도 축소되지 않도록 주의해야 합니다.

- **Min/Max/Desired 값 설정**: Auto Scaling 그룹 생성 시 **최소 인스턴스 수 (Min)**를 설정하는데, 이는 *절대 줄이지 않을 안전 마진*입니다. 프로덕션 서비스라면 Min을 1 이상 (또는 멀티 AZ일 경우 AZ당 1개씩 등)으로 설정합니다. **최대 값 (Max)**은 비용 관리 측면에서 중요합니다. 실수나 버그로 폭증하지 않도록 합리적인 상한을 정합니다 (예: 예상 최대치의 1.5배 등). **초기 Desired**는 현재 트래픽에 맞게 설정하고 배포하며, 이후 Auto Scaling이 조정합니다.

- **모니터링과 재조정**: Auto Scaling 정책 적용 후 **CloudWatch Alarm 히스토리**나 **동적 정책의 활동 로그**(Scaling Activities)를 모니터링하세요. 너무 자주 스케일링 이벤트가 발생하면 임계치나 목표값을 조정하고 쿨다운을 늘립니다. 반대로 스케일링이 늦어서 CPU가 오래 100%였다면 트리거 조건을 완화합니다.

- **여러 정책 조합**: 하나의 Auto Scaling 그룹에 **여러 개의 정책**을 적용할 수도 있습니다. AWS는 **가장 보수적인 결과**를 택합니다. 예를 들어 Target Tracking(50% CPU)과 Step Scaling(90% CPU 시 급증시 +5) 두 개를 넣으면, 평소에는 TT로 작동하다가 90%를 넘는 극한 상황에서는 Step Scaling이 추가 증설해주는 형태가 가능합니다. 다만 복잡성 증가로 권장되진 않지만, 특정 이벤트 대응이 필요하다면 고려합니다.

- **예측 스케일링**: AWS Auto Scaling에서 **예측 scaling** 기능을 사용하면, 지난 14일치 패턴을 학습하여 미리 인스턴스를 증설해 둘 수 있습니다. 예를 들어 매일 9시 트래픽 쏠림이 있다면 8:50에 미리 인스턴스를 늘려 큐잉 없이 처리하게 할 수 있습니다. 이 기능은 콘솔 또는 CLI (`--predictive-scaling-mode`)로 설정 가능하며, 특히 규칙적인 업무시간 트래픽이나 월간 이벤트에 유용합니다. 예측이 잘 맞으면 **컷오버 순간의 과부하를 방지하여 성능을 높이고, 필요 없는 시간에는 자동 축소하여 비용도 절감**합니다.

### 사례: 사용량 기반 스케일링 효과

- **스타트업 A**: 소규모 서비스로, 초기에는 비용 절감을 위해 EC2 2대로 고정 운영했습니다. 그러나 트래픽 변동으로 한때 응답 지연이 생기자 **CPU 60% 타겟 추적 Auto Scaling**을 도입했습니다. 그 결과 피크 시에는 최대 6대까지 자동 확장되어 성능 이슈를 해소했고, 한산한 야간에는 1대로 축소되어 **별도 모니터링 없이도 비용 최적화**가 이뤄졌습니다. 월말 청구서 비교 결과 Auto Scaling 미적용 대비 30% 절감되었습니다 (클라우드 비용이 사용량에 맞춰 최적화된 덕분).

- **엔터프라이즈 B**: 대형 온라인 서비스 기업은 이미 Auto Scaling을 쓰고 있었지만, **메모리 누수 이슈**로 인해 CPU는 낮아도 메모리가 꽉 차 장애가 발생한 적이 있습니다. 이를 해결하기 위해 **메모리 사용률 80% 초과시 증설**하는 커스텀 지표 스케일링을 추가 도입했습니다. 이후 메모리로 인한 장애 없이 안정적 운영이 가능해졌고, 오히려 메모리 기반 증설로 CPU 여유가 늘어나 일부 인스턴스를 줄일 수 있어 비용도 약간 감소했습니다.

- **빅데이터 배치 플랫폼**: 한 엔터프라이즈 R&D 부서는 밤에 돌아가는 데이터 처리 파이프라인 서버를 Auto Scaling으로 구성하여, **작업 큐 길이**가 일정 수준 이상일 때만 인스턴스를 늘리고, 처리가 끝나면 모두 줄이는 방식을 썼습니다. 이를 통해 **필요할 때만 수십 대의 워커 노드를 가동**하고, 평소에는 0~1대만 유지하여, 연중 상시 켜둘 때와 비교해 80% 이상의 비용을 아꼈습니다. (SQS 큐 기반 스케일링 활용 사례)

요약하면, **사용량 기반 오토 스케일링**은 AWS 클라우드 운영의 기본 원칙이며, 잘 활용하면 **성능 보장과 비용 최적화** 두 가지를 모두 만족할 수 있습니다. 중요한 것은 **정확한 지표 선정**과 **적절한 임계값 튜닝**이며, 이를 위해 초기에 충분한 실험과 모니터링이 필요합니다.

## 5. 클라우드 비용 최적화 **최신 사례 및 연구** (2022~2025)

최근 3년 사이 클라우드 비용 최적화에 대한 관심이 폭발적으로 증가하면서, 다양한 **연구 논문과 사례 보고**가 나오고 있습니다. 단순 비용 절감을 넘어서 **FinOps**(Financial Operations)라는 전문 분야가 생겨날 정도로 체계화되고 있는데, 여기서는 눈여겨볼 만한 최신 동향과 연구 2~3가지를 요약하고, AWS 환경에의 적용 가능성을 살펴보겠습니다.

### 최신 연구 논문 1: **클라우드 비용 최적화 종합 리뷰 (2023)**

2023년 7월 arXiv에 발표된 S. Deochake의 **“Cloud Cost Optimization: A Comprehensive Review of Strategies and Case Studies”** 논문은 다양한 비용 최적화 기법을 총망라하고 있습니다. 이 논문은 **클라우드 가격 모델 (온디맨드, RI, Spot 등) 이해**부터 **리소스 할당 전략 (rightsizing, autoscaling)**, 그리고 **FinOps 문화**까지 폭넓게 다룹니다. 특히 몇 가지 현실 사례를 통해 최적화 효과를 입증했는데:

- 한 사례에서는 **미디어 스트리밍 회사가 Auto Scaling과 Spot 인스턴스를 통해 65% 비용 절감**을 이뤘으며, 다른 사례로 **SaaS 기업이 모니터링을 통해 미사용 리소스를 정리하여 30% 절감**한 이야기가 있습니다 (논문 내 사례, 요약 인용). 이러한 결과는 **“적절한 도구와 기법을 조합하면 상당한 비용 절감이 가능하다”**는 것을 보여줍니다. 논문은 또한 **성공적인 비용 최적화의 핵심은 조직의 문화와 프로세스**임을 강조하며, 기술적 기법 외에 **지속적 모니터링, 팀 KPI 연계, 경영진 지원** 등의 중요성을 언급합니다.

- 이 논문에서 제시된 전략들은 대부분 AWS에 바로 적용 가능합니다. 예를 들어 **RI/Spot 혼용 전략**, **자동화된 스케일링**, **Storage 비용 최적화(미사용 EBS 스냅샷 정리)** 등은 AWS Well-Architected Framework의 권고와 일치합니다. 따라서 이 연구의 시사점은, **AWS 사용자도 기본으로 제공되는 Cost Explorer, Compute Optimizer, Auto Scaling, Spot 기능을 총동원하면 좋은 결과를 얻을 수 있다**는 것입니다. 또한 향후 연구 방향으로 **AI를 활용한 비용 예측 및 최적화 자동화**를 제안하고 있는데, AWS에서도 Cost Anomaly Detection이나 ML 기반 예측 스케일링 등 유사한 노력을 기울이고 있어 흥미로운 대목입니다.

### 최신 연구 논문 2: **FinOps 및 예산 관리 자동화 (2024)**

2024년 12월 발표된 **“ABACUS: Automated Budget Analysis and Cloud Usage Surveillance”** 연구 ([](https://arxiv.org/pdf/2501.14753#:~:text=ABACUS%20,finops%C2%B7%20cost%20management%C2%B7%20cloud%20cost))는 기업의 예산 기반 비용 통제에 초점을 맞춘 FinOps 솔루션을 소개합니다. 이 논문은 **클라우드 비용을 단순 절감이 아니라 예산 준수 측면에서 최적화**하는 접근법을 보여줍니다. 주요 내용:

- **예산 설정과 모니터링**: 팀/프로젝트별로 클라우드 예산을 설정하고 실시간으로 사용량을 추적하여, **예산 임계치 도달 시 알림** 또는 심지어 **새 리소스 생성 차단**까지 자동화합니다 ([](https://arxiv.org/pdf/2501.14753#:~:text=Surveillance%2C%20a%20FinOps%20solution%20for,cloud%20optimization%C2%B7%20cloud%20automation%C2%B7%20economics)).
- **사전 코스트 예측**: 인프라를 코드(IaC)로 배포할 때, 예상 비용을 산출하여 **디플로이 전에 팀에 비용 경고**를 주는 기능도 제안합니다 ([](https://arxiv.org/pdf/2501.14753#:~:text=and%20alerting%20appropriate%20teams%20if,Finally%2C%20future%20research%20directions%20are)). 이는 개발 단계부터 비용을 고려하게 만드는 FinOps 문화 정착에 기여합니다.
- **비용 원인 분석**: 비용을 단순히 줄이는 데서 나아가, **비용 발생 카테고리별 분류**(예: 사고 대응 비용, R&D 실험 비용 등)로 **비용 대비 가치**를 평가하도록 합니다 ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=You%20mentioned%20tracking%20costs%20by,of%20opportunities%20to%20save%20money)) ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=%3E%20What%27s%20a%20,utilization%20which%20doesn%27t%20feel%20right)). 이로써 단순 인스턴스 비용뿐 아니라, **클라우드 투자 대비 ROI**를 극대화하는 방향으로 의사결정을 돕습니다.

이 연구는 AWS 환경에서도 응용될 수 있습니다. AWS에서는 **AWS Budgets** 서비스를 통해 예산을 설정하고 알람을 받을 수 있으며, **Service Control Policies(SCP)**와 연계하면 예산 초과 시 특정 행동(예: 새 리소스 생성 금지)을 구현 가능합니다. 또한 IaC 툴(Terraform, CloudFormation)과 비용 산정 API(Cost Explorer 혹은 예측 API)를 결합하면 **배포 전 비용 예측**도 현실화할 수 있습니다. 다만 현재 AWS가 기본 제공하진 않는 기능이므로, 이 논문에서 제시한 ABACUS 같은 추가 솔루션 구현이 필요합니다. 최근에는 오픈소스 FinOps OSS나 상용 툴(CloudZero, Spot.io etc.)이 이러한 예산 관리 자동화를 일부 제공하기 시작했으므로, AWS 고객들도 이를 도입하는 추세입니다.

### 최신 사례 3: **스포트 인스턴스 최적화 및 AI 도입**

커뮤니티와 AWS 발표에서 나타난 최근 경향 중 하나는, **스팟 인스턴스 활용을 더욱 지능화**하는 것입니다. 2023~2024년 사이 몇몇 스타트업과 학계에서는 **강화학습(RL)**이나 **유전 알고리즘**을 활용하여 **스팟 인스턴스 기반의 최적 스케줄링**을 연구했습니다 ([Adaptive Spot-Instances Aware Autoscaling for Scientific Workflows ...](https://www.researchgate.net/publication/267325873_Adaptive_Spot-Instances_Aware_Autoscaling_for_Scientific_Workflows_on_the_Cloud#:~:text=Adaptive%20Spot,In%20this%20work%2C%20tasks)). 예를 들어 **SpotKube**라는 오픈소스 프로젝트는 Kubernetes 환경에서 **유전 알고리즘으로 비용 최적화된 노드 할당**을 구현하여, 온디맨드와 스팟의 최적 조합을 자동으로 찾아냅니다 ([SpotKube: Cost-Optimal Microservices Deployment with Cluster ...](https://arxiv.org/html/2405.12311v2#:~:text=SpotKube%3A%20Cost,compare%20its%20effectiveness%20with)) ([SpotKube: Cost-Optimal Microservices Deployment with Cluster ...](https://arxiv.org/html/2405.12311v2#:~:text=In%20this%20paper%2C%20we%20evaluate,compare%20its%20effectiveness%20with)). 이러한 접근은 사람의 설정에 의존하던 것을 AI가 동적으로 최적화한다는 면에서 주목받습니다.

AWS 자체도 2023년 말 re:Invent에서 **“스팟 인스턴스 활용 극대화”** 세션을 통해, **Spot Placement Score**라는 새로운 지표를 소개했습니다. 이는 특정 리전/가용영역에서 스팟 수요를 만족시킬 수 있는지 점수로 보여주는 기능으로, 사용자가 스팟 클러스터를 어디에 돌릴지 결정하는 데 도움을 줍니다 ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=In%20this%20blog%20post%2C%20we,Amazon%20EC2%20Auto%20Scaling%20groups)) ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=1)). 또한 **예측 스팟 가격 모델** 고도화, EC2 내부 스케줄링 최적화 등도 진행 중입니다. 이러한 최신 기법들은 아직 논문 단계이거나 특정 프레임워크 한정이지만, AWS도 빠르게 참조하여 Managed 서비스에 녹여내는 추세입니다. 예를 들어 **AWS Fault Injection Simulator와 Spot**의 결합 사용이나, Data Lifecycle Manager를 통한 **비용-성능 밸런싱** 등이 권고되고 있습니다.

### 최신 사례 4: **Rightsizing + 데이터 절감 통합 접근**

최신 비용 최적화 담론에서는 컴퓨팅뿐 아니라 **스토리지, 데이터 전송 비용**까지 아우르는 **총체적 최적화**가 강조됩니다. 2022년 한 연구는 **“Saving Money for Analytical Workloads in the Cloud”** ([Saving Money for Analytical Workloads in the Cloud](https://arxiv.org/html/2408.00253v1#:~:text=As%20users%20migrate%20their%20analytical,We%20reduce))에서 **OLAP 쿼리의 코스트 모델**을 분석하여, **I/O 바운드 쿼리는 I/O 기반 과금 모델(BigQuery같이)**, **CPU 바운드 쿼리는 시간 과금 모델(Redshift같이)**로 실행 계획을 튜닝하면 최대 56% 비용을 절감할 수 있다고 밝혔습니다 ([Saving Money for Analytical Workloads in the Cloud](https://arxiv.org/html/2408.00253v1#:~:text=In%20the%20cloud%2C%20a%20query,To%20study%20this%20effect%2C%20we)) ([Saving Money for Analytical Workloads in the Cloud](https://arxiv.org/html/2408.00253v1#:~:text=analytical%20workloads%20in%20the%20cloud,with%20a%20favorable%20pricing%20model)). 이는 멀티클라우드나 하이브리드 환경에서 **워크로드별 최적의 서비스 조합**을 찾는 연구로, AWS에서도 Redshift Spectrum, Athena 등 다양한 서비스 조합으로 비슷한 효과를 낼 수 있습니다.

또 다른 2022년 연구에서는 **서버리스 엣지 컴퓨팅 비용 최적화**를 다뤘는데, 이는 IoT/Edge 쪽에서 **지연시간 요구사항을 만족하면서 비용을 줄이는 함수 배치**에 관한 것입니다 ([Cost Optimization for Serverless Edge Computing with Budget ...](https://arxiv.org/html/2501.12783v2#:~:text=Cost%20Optimization%20for%20Serverless%20Edge,This)). AWS Lambda@Edge나 CloudFront Functions 등을 활용한 엣지 컴퓨팅에서도 비용/성능 절충을 최적화하는 방향으로 연구가 진행 중이며, 향후 AWS 제품 개선에 반영될 수 있습니다.

마지막으로, **FinOps 문화** 측면에서 최근 2023년에 발표된 **AWS 사용자 사례**들에서는, **조직에 비용 최적화 책임자를 두고 주기적으로 리소스 사용을 리뷰**하는 습관을 들인 곳은 연 30% 이상의 비용 감소를 이루었다고 보고합니다. 예컨대 한 게임 업체는 월간 “Cost Optimization Day”를 운영하여 모든 팀이 그달의 클라우드 지출을 리뷰하고 필요 없는 리소스를 정리하도록 장려하여, 1년 만에 수억 원을 절감했다고 합니다 (AWS PT 발표, 2023).

### AWS 환경 적용 가능성 평가

위의 최신 연구/사례들을 종합해보면, **AWS 사용자는 이미 활용 가능한 도구들이 많아** 대부분의 전략을 바로 시도해볼 수 있습니다:

- FinOps 예산 관리 -> **AWS Budgets, Cost Anomaly Detection** 활용 + 조직 문화 도입.
- AI 기반 최적화 -> 아직 성숙 단계는 아니나, **AWS Compute Optimizer**나 Third-party SaaS (Spot.io, Zesty 등) 활용 가능.
- 멀티 가격 모델 -> AWS 내에서도 **Savings Plans vs Spot vs Lambda** 혼용으로 유사 효과 달성 가능.
- 데이터 전송/저장 최적화 -> **CloudFront, S3 Intelligent Tiering, Egress 패턴 최적화** 등으로 대응.

결론적으로, 2022년 이후의 최신 연구들은 **보다 지능적이고 총체적인 비용 최적화**를 지향하고 있으며, AWS도 이러한 흐름에 맞춰 서비스와 기능을 확장하고 있습니다. **핵심은 여전히 자원의 탄력적 운영과 적절한 구매 옵션 선택**이며, 여기에 **자동화와 예산 관리를 결합**하는 것이 최신 트렌드라 할 수 있습니다. AWS 환경에서 즉시 적용하려면, 위에서 다룬 기술적 방법론들을 적극 활용하고, 새로운 서비스를 (예: 스팟 플레이스먼트 스코어) 도입함과 동시에, 조직적으로도 **비용 최적화 KPI 설정과 인센티브**를 주어 **지속 가능한 최적화**를 추진해야 할 것입니다 ([](https://arxiv.org/pdf/2501.14753#:~:text=In%20today%E2%80%99s%20fast,based%20businesses%20are%20shifting)) ([AWS cost optimization pattern : r/aws](https://www.reddit.com/r/aws/comments/108igiy/aws_cost_optimization_pattern/#:~:text=%3E%20What%27s%20a%20,utilization%20which%20doesn%27t%20feel%20right)).

---

**참고 자료:** 본 답변에서는 AWS 공식 문서와 블로그 ([Auto Scaling groups with multiple instance types and purchase options - Amazon EC2 Auto Scaling](https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-mixed-instances-groups.html#:~:text=You%20can%20launch%20and%20automatically,and%20performance%20for%20your%20application)) ([Best practices to optimize your Amazon EC2 Spot Instances usage | AWS Compute Blog](https://aws.amazon.com/blogs/compute/best-practices-to-optimize-your-amazon-ec2-spot-instances-usage/#:~:text=Amazon%20EC2%20Spot%20Instances%20,Instances%20by%20following%20best%20practices)), 사례 연구 ([Scaling Up to 30% While Reducing Costs by 20% Using AWS Graviton3 Processors with Instructure | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/instructure-case-study/#:~:text=Up%20to%2030)) ([Cutting Workload Cost by up to 50% by Scaling on Spot Instances and AWS Graviton with SmartNews | Case Study | AWS](https://aws.amazon.com/solutions/case-studies/smartnews-graviton-case-study/#:~:text=Solution%20%7C%C2%A0Reducing%20Main,50%20Percent%20Using%20Spot%20Instances)), 및 최신 연구 논문 ([](https://arxiv.org/pdf/2501.14753#:~:text=ABACUS%20,finops%C2%B7%20cost%20management%C2%B7%20cloud%20cost)) 등을 인용하여 내용을 구성하였습니다. 최신 정보(2022~2025)를 기반으로 했으나, AWS 서비스는 계속 진화하므로 적용 시점의 최신 문서를 한 번 더 참조하기를 권장합니다.
